{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4970d171",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# Tutorial adversarial MIP attacks : Sparse and invisible adversarial attacks using MIP Optimization\n",
    "\n",
    "In this notebook we are dealing specifically with sparse adversarial attacks for neural networks with feedforward, convolutional, and residual layers. We want to modify the smallest amount of pixels in order to change the decision. We propose a new technique to craft adversarial examples aiming at minimizing $\\ell_1$ distance to the original image regularized by the Total variation (TV) function. This will favor the change of pixels in the region of high variation making the attacks almost invisible.\n",
    "\n",
    "This notebook implements main methods to generate such adversarial MIPs examples in a white box setting, with the CIFAR10 and Mnist datasets using several neural networks used in [Eran](https://files.sri.inf.ethz.ch/eran/docs/eran_manual.pdf), in order to compare their efficiency in terms of accuracy, solution quality and computation time.\n",
    "\n",
    "\n",
    "\n",
    "We can use the CIFAR10 dataset, in which there ares images belonging to $c = 10$ possible labels {\"airplane\",\n",
    "        \"automobile\",\n",
    "        \"bird\",\n",
    "        \"cat\",\n",
    "        \"deer\",\n",
    "        \"dog\",\n",
    "        \"frog\",\n",
    "        \"horse\",\n",
    "        \"ship\",\n",
    "        \"truck\"}.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://www.cs.umd.edu/~tomg/img/free/viz_9985_10000_small.png\" \n",
    "alt=\"CIFAR10 data\" width=\"360\" height=\"270\" border=\"1\"/>\n",
    "<p style=\"text-align: center;\"> <i>Illustration from the Adversarial Training for Free! web site </i> https://www.cs.umd.edu/~tomg/projects/free/</p>\n",
    "</center>\n",
    "\n",
    "Or we can use the Mnist dataset, in which there ares images belonging to $c = 10$ possible labels { \"zero\",\n",
    "            \"one\",\n",
    "            \"two\",\n",
    "            \"three\",\n",
    "            \"four\",\n",
    "            \"five\",\n",
    "            \"sex\",\n",
    "            \"seven\",\n",
    "            \"eight\",\n",
    "            \"nine\"}.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f7/MnistExamplesModified.png\" \n",
    "alt=\"Mnist data\" width=\"360\" height=\"270\" border=\"1\"/>\n",
    "<p style=\"text-align: center;\"> <i>Illustration from the Adversarial Training for Free! web site </i> https://en.wikipedia.org/wiki/MNIST_database</p>\n",
    "</center>\n",
    "\n",
    "\n",
    "Are implemented:\n",
    "- The MIP-ReLUplex-gurobi attacks using $L_{inf}$ distance measure\n",
    "- The MIP-ReLUplex-gurobi attacks using $L_2$ distance measure\n",
    "- The MIP-ReLUplex-gurobi attacks using $L_1$  distance measure\n",
    "- The MIP-ReLUplex-gurobi attacks using $L_1$  distance measure + TV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20fe883f",
   "metadata": {
    "cell_style": "center",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 07:29:18.663385: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/gurobi952/linux64/lib\n",
      "2023-06-12 07:29:18.663434: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-12 07:29:22.854459: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-12 07:29:22.949765: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/gurobi952/linux64/lib\n",
      "2023-06-12 07:29:22.949827: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-12 07:29:22.949862: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (calcul-02): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import onnxruntime.backend as rt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from onnx import helper\n",
    "\n",
    "sys.path.insert(0, \"./ELINA/python_interface/\")\n",
    "sys.path.insert(1, \"./ERAN/\")\n",
    "\n",
    "from config import config\n",
    "from ipynb.fs.full.ai_milp import *\n",
    "from read_net_file import *\n",
    "\n",
    "from eran import ERAN\n",
    "\n",
    "is_tf_version_2 = tf.__version__[0] == \"2\"\n",
    "if is_tf_version_2:\n",
    "    tf = tf.compat.v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef1c816",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "## Loading Data and trained neural network\n",
    "\n",
    "The code can read neural networks in ONNX and TensorFlow formats directly. Both formats\n",
    "are based on a computation graph. The nodes of this directed acyclic graph save the operations\n",
    "and parameters needed for the execution. One of the main differences between the two formats\n",
    "is in the representation of tensors. TensorFlow uses NHWC (batch, height, width, channel)\n",
    "while ONNX uses NCHW representation\n",
    "\n",
    "<center>\n",
    "<img src=\"https://www.researchgate.net/publication/321259051/figure/fig1/AS:614329250496529@1523478915726/Artificial-neural-network-architecture-ANN-i-h-1-h-2-h-n-o.png\" \n",
    "alt=\"Artificial neural network architecturea\" width=\"360\" height=\"270\" border=\"1\"/>\n",
    "<p style=\"text-align: center;\"> <i>Artificial neural network architecture! [web site] (https://www.researchgate.net/figure/Artificial-neural-network-architecture-ANN-i-h-1-h-2-h-n-o_fig1_321259051)\n",
    "</center>\n",
    "    \n",
    "Choose a network, the name of a dataset, and the folder where the dataset is stored. The code determines the type of the selected network and reads it using TensorFlow or ONNX. Finally, the code sets the means and standard deviations of the dataset based on whether the network is normalized or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132d7ca8",
   "metadata": {
    "cell_style": "center",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset to test :  mnist\n",
      "0 : mnist_relu_6_100.onnx\n",
      "1 : mnist_relu_9_200.onnx\n",
      "2 : mnist_relu_3_50.onnx\n",
      "3 : convSmallRELU__Point.onnx\n",
      "4 : convMedGRELU__Point.onnx\n",
      "5 : mnist_relu_3_100.onnx\n",
      "6 : mnist_conv_maxpool.onnx\n",
      "\n",
      "Network to test :  2 : mnist_relu_3_50.onnx\n"
     ]
    }
   ],
   "source": [
    "dataset = \"mnist\" #mnist ou cifar10\n",
    "print(\"\\n Dataset to test : \", dataset)\n",
    "# uses the os module to get a list of networks in the dataset folder and selects one based on the index\n",
    "idx_network = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "domain = \"deeppoly\"\n",
    "is_gpupoly = False\n",
    "\n",
    "if dataset == \"cifar10\":\n",
    "    class_names = [\n",
    "        \"airplane\",\n",
    "        \"automobile\",\n",
    "        \"bird\",\n",
    "        \"cat\",\n",
    "        \"deer\",\n",
    "        \"dog\",\n",
    "        \"frog\",\n",
    "        \"horse\",\n",
    "        \"ship\",\n",
    "        \"truck\",\n",
    "    ]\n",
    "else : \n",
    "    class_names = [\n",
    "            \"zero\",\n",
    "            \"one\",\n",
    "            \"two\",\n",
    "            \"three\",\n",
    "            \"four\",\n",
    "            \"five\",\n",
    "            \"sex\",\n",
    "            \"seven\",\n",
    "            \"eight\",\n",
    "            \"nine\",\n",
    "        ]\n",
    "    \n",
    "dataset_folder = \"./data/\" + dataset + \"/nets/\"\n",
    "\n",
    "networks = os.listdir(dataset_folder)\n",
    "\n",
    "for i, val in enumerate(networks):\n",
    "    print(i, \":\", val)\n",
    "\n",
    "\n",
    "network = networks[idx_network]\n",
    "print(\"\\nNetwork to test : \", idx_network, \":\", network)\n",
    "\n",
    "filename = \"./data/\" + dataset + \"/test.csv\"\n",
    "\n",
    "tf.reset_default_graph()\n",
    "netname = dataset_folder + network\n",
    "filename, file_extension = os.path.splitext(netname)\n",
    "\n",
    "is_trained_with_pytorch = file_extension == \".pyt\"\n",
    "is_saved_tf_model = file_extension == \".meta\"\n",
    "is_pb_file = file_extension == \".pb\"\n",
    "is_tensorflow = file_extension == \".tf\"\n",
    "is_onnx = file_extension == \".onnx\"\n",
    "\n",
    "complete = True\n",
    "\n",
    "if is_saved_tf_model or is_pb_file:\n",
    "    print(\"is_saved_tf_model or is_pb_file\")\n",
    "else:\n",
    "    if dataset == \"mnist\":\n",
    "        num_pixels = 784\n",
    "    elif dataset == \"cifar10\":\n",
    "        num_pixels = 3072\n",
    "    elif dataset == \"acasxu\":\n",
    "        num_pixels = 5\n",
    "    if is_onnx:\n",
    "        model, is_conv = read_onnx_net(netname)\n",
    "    else:\n",
    "        sess = tf.Session()\n",
    "        model, is_conv, means, stds = read_tensorflow_net(\n",
    "            netname, num_pixels, is_trained_with_pytorch, is_gpupoly\n",
    "        )\n",
    "\n",
    "if is_conv:\n",
    "    print(\"This network is conv\")\n",
    "\n",
    "is_normalized = False\n",
    "\n",
    "if is_normalized:\n",
    "    print(\"This network is normalized\")\n",
    "    means = [0.4914, 0.48220003, 0.4465]\n",
    "    stds = [0.20230001, 0.19940001, 0.201]\n",
    "else:\n",
    "    means = [0, 0, 0]\n",
    "    stds = [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b318bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of [0.] extracted from network\n",
      "Std of [1.] extracted from network\n",
      "This network has 110 neurons.\n"
     ]
    }
   ],
   "source": [
    "eran = ERAN(model, is_onnx=is_onnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c588d-089f-4d5c-afc6-125cf55b3730",
   "metadata": {
    "cell_style": "center",
    "tags": []
   },
   "source": [
    "## Loading and Normalize data \n",
    "\n",
    "We reads in a CSV file containing test data for a given dataset, skips the first four rows, and extracts an image and its corresponding label from the next row. It then defines a function for displaying three images, and normalizes the image data. Depending on the dataset, it reshapes the input data, and then plots the original image and two additional images: one with added noise and one after an attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5f3248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "csvfile = open(\"./data/\" + dataset + \"/test.csv\", \"r\")\n",
    "tests = csv.reader(csvfile, delimiter=\",\")\n",
    "\n",
    "next(tests)\n",
    "next(tests)\n",
    "next(tests)\n",
    "next(tests)\n",
    "\n",
    "test = next(tests)\n",
    "image = np.float64(test[1 : len(test)]) / np.float64(255)\n",
    "Image_label = np.int(test[0])\n",
    "test_input = np.copy(image)\n",
    "\n",
    "\n",
    "def imshow(img, fig):\n",
    "    img = img\n",
    "    npimg = img.numpy()\n",
    "    fig.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "def plot_attack_pred(original, label_name, attack, label_name_a):\n",
    "    # show image and noise\n",
    "    ax, fig = plt.subplots(nrows=1, ncols=3, figsize=(10, 8))\n",
    "    fig[0].set_title(\"Original -> Label : \" + label_name)\n",
    "    imshow(torchvision.utils.make_grid(original), fig[0])\n",
    "    noise = (original - attack).detach()\n",
    "    fig[1].set_title(\"Noise added\")\n",
    "    imshow(10 * torchvision.utils.make_grid(noise), fig[1])\n",
    "    fig[2].set_title(\"Attak -> Label : \" + label_name_a)\n",
    "    imshow(torchvision.utils.make_grid(attack), fig[2])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if dataset == \"cifar10\":\n",
    "    # input = np.array(test_input, dtype=np.float32).reshape([1, 32, 32, 3])\n",
    "    input2 = torch.tensor(test_input).reshape((3, 32, 32)).type(torch.float)\n",
    "elif dataset == \"mnist\":\n",
    "    input = np.array(test_input, dtype=np.float32).reshape([1, 28, 28, 1])\n",
    "    input2 = torch.tensor(test_input).reshape((1, 28, 28)).type(torch.float)\n",
    "\n",
    "def normalize(image, means, stds, dataset):\n",
    "    # normalization taken out of the network\n",
    "    if len(means) == len(image):\n",
    "        for i in range(len(image)):\n",
    "            image[i] -= means[i]\n",
    "            if stds != None:\n",
    "                image[i] /= stds[i]\n",
    "    elif dataset == \"mnist\" or dataset == \"fashion\":\n",
    "        for i in range(len(image)):\n",
    "            image[i] = (image[i] - means[0]) / stds[0]\n",
    "    elif dataset == \"cifar10\":\n",
    "        count = 0\n",
    "        tmp = np.zeros(3072)\n",
    "        for i in range(1024):\n",
    "            tmp[count] = (image[count] - means[0]) / stds[0]\n",
    "            count = count + 1\n",
    "            tmp[count] = (image[count] - means[1]) / stds[1]\n",
    "            count = count + 1\n",
    "            tmp[count] = (image[count] - means[2]) / stds[2]\n",
    "            count = count + 1\n",
    "\n",
    "        is_gpupoly = False\n",
    "        if is_conv and not is_gpupoly:\n",
    "            for i in range(3072):\n",
    "                image[i] = tmp[i]\n",
    "        else:\n",
    "            count = 0\n",
    "            for i in range(1024):\n",
    "                image[i] = tmp[count]\n",
    "                count = count + 1\n",
    "                image[i + 1024] = tmp[count]\n",
    "                count = count + 1\n",
    "                image[i + 2048] = tmp[count]\n",
    "                count = count + 1\n",
    "\n",
    "\n",
    "test_input = np.copy(image)\n",
    "image_norm = np.copy(image)\n",
    "normalize(image_norm, means, stds, dataset)\n",
    "\n",
    "\n",
    "if dataset == \"cifar10\":\n",
    "    input = np.array(image_norm, dtype=np.float32).reshape([1, 32, 32, 3])\n",
    "    input2 = torch.tensor(image_norm).reshape((3, 32, 32)).type(torch.float)\n",
    "elif dataset == \"mnist\":\n",
    "    input = np.array(image_norm, dtype=np.float32).reshape([1, 28, 28, 1])\n",
    "    input2 = torch.tensor(image_norm).reshape((1, 28, 28)).type(torch.float)\n",
    "\n",
    "\n",
    "\n",
    "if is_conv:\n",
    "    plot_attack_pred(\n",
    "        torch.from_numpy(input).permute(0, 3, 1, 2).to(\"cpu\"),\n",
    "        class_names[Image_label],\n",
    "        torch.from_numpy(input).permute(0, 3, 1, 2).to(\"cpu\"),\n",
    "        class_names[Image_label],\n",
    "    )\n",
    "else:\n",
    "    plot_attack_pred(\n",
    "        input2,\n",
    "        class_names[Image_label],\n",
    "        input2,\n",
    "        class_names[Image_label],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a031b723-6b80-427a-b5b1-32bd92923129",
   "metadata": {},
   "source": [
    "IRAN is used to get Lower and Upper Bounds of the neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbc6838e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 5, 6, 7, 8, 9]\n",
      "-> network not robuste\n"
     ]
    }
   ],
   "source": [
    "specLB = np.copy(image_norm)\n",
    "specUB = np.copy(image_norm)\n",
    "\n",
    "eps    = 0.1\n",
    "\n",
    "specLB = specLB - eps\n",
    "specUB = specUB + eps\n",
    "\n",
    "specLB[specLB < 0] = 0\n",
    "specUB[specUB > 1] = 1\n",
    "\n",
    "label_pred, nn, nlb, nub, failed_labels, x = eran.analyze_box(\n",
    "    specLB, specUB, domain, 1, 1, config.use_default_heuristic, label=Image_label, testing=False, terminate_on_failure=False, max_milp_neurons=1000, complete=True\n",
    ")\n",
    "print(failed_labels)\n",
    "\n",
    "\n",
    "if label_pred != -1:\n",
    "    print(\"Label predicted :\", label_pred, \"-> \", class_names[label_pred])\n",
    "else:\n",
    "    print(\"-> network not robuste\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0232199b-8757-4b3e-98fb-2b8472025399",
   "metadata": {},
   "source": [
    "Choose the attack target :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0287baf8-eebd-4734-a03a-e238ec2ba43a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack target : 9 ->  nine\n"
     ]
    }
   ],
   "source": [
    "adv_label = 9\n",
    "print(\"Attack target :\", adv_label, \"-> \", class_names[adv_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ccfe69-a657-4088-be18-1e0757a2b632",
   "metadata": {},
   "source": [
    "## MIPs adversarial exemples\n",
    "\n",
    "A classification model (e.g. Neural Network) with $c$  output nodes  (possible classes)\n",
    "\\begin{equation*}\n",
    "\t\\begin{array}{cccl}\n",
    "\t\tf : {} & X \\subseteq \\mathbb{R}^p &  \\longrightarrow&  \\mathbb{R}^c  \\\\ %  \\{0,1\\}^c \\\\\n",
    "\t\t{} & x &  \\longmapsto& f(x)\n",
    "\t\\end{array}\n",
    "\t\\label{function-neural-network}\n",
    "\\end{equation*}\n",
    "The associated classification (or decision function) \n",
    "$$\n",
    "C_f(x) = argmax_{k=1,\\dots,c} f_k(x)\n",
    "$$\n",
    "\n",
    "Definition (Generic adversarial example): \n",
    "$\\mathbf{a}_{f,x}$ is a generic adversarial example of $f$ at $x$ if $\\mathbf{a}_{f,x}$ is a valid input close to $x$  and    \n",
    "$$ \n",
    "C_f(x) \\neq C_f(\\mathbf{a}_{f,x})\n",
    "\\quad \\mbox{ that is } \\quad \n",
    " \\displaystyle  {c^\\star} =  argmax_{k=1,\\dots,c} f_k(x) \\neq argmax_{k=1,\\dots,c} f_k(\\mathbf{a}_{f,x})\n",
    " $$\n",
    "\n",
    "It is also possible to exactly minimize the  Adversarial  Distortion \n",
    "\\begin{equation}\n",
    "\t\\left\\{\n",
    "\t\\begin{array}{cclc}\n",
    "\t\t\\displaystyle \\min_{a \\in X }  &D(x,a) &=&  \\|x-a\\|_p^p \\\\\n",
    "\t\t\\text{subject to} & L\\bigl(f(x),f(a)\\bigr) \\geq \\alpha  &=&\\displaystyle \\max_{k \\neq {c^\\star}} f_k(a) >  f_{c^\\star}(a) + \\alpha\n",
    "\t\\end{array}\n",
    "\t\\right.\n",
    "\t\\label{eq:MIP}\n",
    "\\end{equation}\n",
    "In the particular case of a one hidden layer MLP with weighe $W$ and $V$ and biais $\\beta$ and $\\gamma$, function $f$ is\n",
    "$$\n",
    "\t\\begin{array}{rl}\n",
    "\t\t\\displaystyle \n",
    "\t\tz  & =  ReLU(W x + \\beta)\\\\\n",
    "\t\tf(x) & = V z + \\gamma\n",
    "\t\\end{array}\n",
    "\t\\quad \\text{or}\\quad \n",
    "\t\\begin{array}{rl}\n",
    "\t\t\\displaystyle \n",
    "\t\th & = W x + \\beta,\\\\\n",
    "\t\tz  & =  \\max(h, 0)\\\\\n",
    "\t\tf(x) = s  & = V z + \\gamma \\,.\n",
    "\t\\end{array}\n",
    "$$\n",
    "Based on that, the minimization of the  Adversarial  Distortion can be rewritten as a Mixed Integer Linear Program (MILP)\n",
    "\n",
    "\n",
    "We create the MIP model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "715ef175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_model -\n",
      "Set parameter Username\n",
      "Set parameter TokenServer to value \"calcul-02\"\n",
      "Set parameter FeasibilityTol to value 2.0000000000000002e-05\n",
      "milp_encode_idx neurons  50\n",
      "milp_encode_idx neurons  50\n",
      "milp_encode_idx neurons  10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gurobi.Constr *Awaiting Model Update*>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "relu_groups = None\n",
    "use_milp = True\n",
    "complete = True\n",
    "\n",
    "is_nchw = False\n",
    "partial_milp = -1\n",
    "max_milp_neurons = 5000\n",
    "\n",
    "\n",
    "counter, var_list, model = create_model(\n",
    "    nn,\n",
    "    specLB,\n",
    "    specUB,\n",
    "    nlb,\n",
    "    nub,\n",
    "    relu_groups,\n",
    "    nn.numlayer,\n",
    "    use_milp,\n",
    "    is_nchw,\n",
    "    partial_milp,\n",
    "    max_milp_neurons,\n",
    ")\n",
    "\n",
    "num_var = len(var_list)\n",
    "output_size = num_var - counter\n",
    "\n",
    "model.addConstr(var_list[counter + adv_label] >= var_list[counter + Image_label] + 0.1)\n",
    "#model.addConstr(var_list[counter + adv_label] >= var_list[counter + 0])\n",
    "#model.addConstr(var_list[counter + adv_label] >= var_list[counter + 1])\n",
    "#model.addConstr(var_list[counter + adv_label] >= var_list[counter + 2])\n",
    "#model.addConstr(var_list[counter + adv_label] >= var_list[counter + 3])\n",
    "#model.addConstr(var_list[counter + adv_label] >= var_list[counter + 4])\n",
    "#model.addConstr(var_list[counter + adv_label] >= var_list[counter + 5])\n",
    "#model.addConstr(var_list[counter + adv_label] >= var_list[counter + 6])\n",
    "#model.addConstr(var_list[counter + adv_label] >= var_list[counter + 7])\n",
    "#model.addConstr(var_list[counter + adv_label] >= var_list[counter + 8])\n",
    "#model.addConstr(var_list[counter + adv_label] >= var_list[counter + 9])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204cad82-60b7-40db-88ec-863648029651",
   "metadata": {},
   "source": [
    "# The MIP-ReLUplex-gurobi attacks using $L_2$ distance measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24002fb3-507b-408c-8871-4474ec6b2a15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 1000\n",
      "Gurobi Optimizer version 9.5.0 build v9.5.0rc5 (linux64)\n",
      "Thread count: 16 physical cores, 16 logical processors, using up to 16 threads\n",
      "Optimize a model with 539 rows, 1110 columns and 43164 nonzeros\n",
      "Model fingerprint: 0x6bfe9385\n",
      "Model has 784 quadratic objective terms\n",
      "Model has 106 general constraints\n",
      "Variable types: 1004 continuous, 106 integer (106 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-06, 4e+01]\n",
      "  Objective range  [4e-02, 2e+00]\n",
      "  QObjective range [2e+00, 2e+00]\n",
      "  Bounds range     [2e-02, 4e+01]\n",
      "  RHS range        [2e-04, 3e+01]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "Presolve removed 12 rows and 10 columns\n",
      "Presolve time: 0.18s\n",
      "Presolved: 527 rows, 1100 columns, 39913 nonzeros\n",
      "Presolved model has 784 quadratic objective terms\n",
      "Variable types: 995 continuous, 105 integer (105 binary)\n",
      "\n",
      "Root relaxation: objective 5.115908e-13, 441 iterations, 0.02 seconds (0.03 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00001    0   47          -    0.00001      -     -    0s\n",
      "     0     0    0.00001    0   49          -    0.00001      -     -    0s\n",
      "     0     0    0.00001    0   49          -    0.00001      -     -    0s\n",
      "     0     0    0.00001    0   52          -    0.00001      -     -    0s\n",
      "     0     0    0.00001    0   52          -    0.00001      -     -    0s\n",
      "     0     0    0.00001    0   43          -    0.00001      -     -    0s\n",
      "H    0     0                       0.9805805    0.00001   100%     -    1s\n",
      "     0     2    0.00001    0   43    0.98059    0.00001   100%     -    1s\n",
      "H   40    44                       0.9755254    0.00001   100%   135    2s\n",
      "H   41    44                       0.9738117    0.00001   100%   132    2s\n",
      "H  178   153                       0.9220585    0.00001   100%  57.3    4s\n",
      "H  179   153                       0.9198387    0.00001   100%  57.6    4s\n",
      "H  181   153                       0.9017636    0.00001   100%  57.4    4s\n",
      "H  182   153                       0.9001581    0.00001   100%  57.1    4s\n",
      "H  184   153                       0.8897906    0.00001   100%  57.9    4s\n",
      "H  191   153                       0.8680263    0.00001   100%  57.0    4s\n",
      "   258   193    0.01065   17   52    0.86803    0.00001   100%  59.5    5s\n",
      "H 1260   860                       0.8203398    0.00001   100%  48.9    8s\n",
      "H 1365   873                       0.6570435    0.00001   100%  49.5   14s\n",
      "H 1366   873                       0.6026837    0.00001   100%  49.5   14s\n",
      "H 1367   873                       0.5958386    0.00001   100%  49.5   14s\n",
      "H 1373   873                       0.5905031    0.00001   100%  49.6   14s\n",
      "  1885  1023    0.13543   38   36    0.59051    0.00001   100%  53.0   15s\n",
      "  2086  1062    0.38509   32   43    0.59051    0.00001   100%  53.1   20s\n",
      "  2443  1252     cutoff   32         0.59051    0.00001   100%  53.7   25s\n",
      "  3645  1438    0.00001   33   32    0.59051    0.00001   100%  58.0   34s\n",
      "H 3651  1382                       0.5899451    0.00001   100%  58.3   34s\n",
      "  3785  1436    0.00001   38   47    0.58995    0.00001   100%  59.2   35s\n",
      "  5555  2025    0.29359   56   30    0.58995    0.00513  99.2%  63.0   40s\n",
      "  8941  3754    0.12680   43   41    0.58995    0.01852  96.9%  60.6   45s\n",
      " 12790  5416     cutoff   56         0.58995    0.03904  93.4%  61.3   50s\n",
      " 16711  6989    0.53414   37   40    0.58995    0.05210  91.2%  61.6   55s\n",
      " 20566  9204    0.24259   54   35    0.58995    0.05459  90.8%  60.7   60s\n",
      " 25649 11470     cutoff   49         0.58995    0.06747  88.6%  59.8   65s\n",
      " 30849 13908    0.37425   56   29    0.58995    0.07524  87.3%  59.2   70s\n",
      " 35540 15743    0.47964   60   30    0.58995    0.08477  85.7%  59.3   75s\n",
      " 41379 18370    0.40566   37   55    0.58995    0.09323  84.2%  58.9   90s\n",
      " 46843 20398     cutoff   58         0.58995    0.09658  83.7%  58.6   95s\n",
      " 51545 22268    0.30874   44   44    0.58995    0.10513  82.2%  58.3  100s\n",
      " 58044 24671     cutoff   45         0.58995    0.11038  81.3%  58.1  106s\n",
      " 63108 26802    0.29860   49   35    0.58995    0.11493  80.6%  57.8  111s\n",
      " 66586 28091     cutoff   44         0.58995    0.11714  80.2%  57.9  115s\n",
      " 71592 29792    0.18933   35   43    0.58995    0.12296  79.2%  57.9  120s\n",
      " 76338 31490    0.17081   45   36    0.58995    0.12505  78.9%  58.1  125s\n",
      " 81425 33309     cutoff   57         0.58995    0.12932  78.1%  57.9  130s\n",
      " 86864 35242    0.36815   48   38    0.58995    0.13268  77.6%  57.6  135s\n",
      " 91433 36820     cutoff   62         0.58995    0.13574  77.0%  57.6  140s\n",
      " 96220 38470    0.41578   51   35    0.58995    0.13931  76.4%  57.5  145s\n",
      " 102870 40888    0.43210   49   39    0.58995    0.14256  75.9%  57.3  151s\n",
      " 108102 42782    0.37942   52   34    0.58995    0.14464  75.5%  57.2  156s\n",
      " 112661 44364    0.29290   47   40    0.58995    0.14757  75.0%  57.3  160s\n",
      " 117407 45930    0.42707   49   48    0.58995    0.14998  74.6%  57.2  166s\n",
      " 122183 47651    0.38175   50   36    0.58995    0.15309  74.1%  57.2  171s\n",
      " 127137 49167    0.36931   48   34    0.58995    0.15659  73.5%  57.1  176s\n",
      " 130528 50196    0.22363   55   35    0.58995    0.15801  73.3%  57.1  180s\n",
      " 135500 51687     cutoff   47         0.58995    0.16156  72.7%  57.1  186s\n",
      " 138753 52581    0.51409   56   32    0.58995    0.16186  72.6%  57.1  190s\n",
      " 143838 53835     cutoff   57         0.58995    0.16695  71.8%  57.0  196s\n",
      " 145769 54984    0.55816   47   46    0.58995    0.16858  71.5%  56.9  200s\n",
      " 151084 56673    0.19268   49   40    0.58995    0.17041  71.2%  56.8  206s\n",
      " 155838 58086    0.53510   44   42    0.58995    0.17210  70.9%  56.8  211s\n",
      " 160407 59535    0.22268   46   45    0.58995    0.17365  70.6%  56.9  216s\n",
      " 165175 60707     cutoff   45         0.58995    0.17713  70.0%  56.9  221s\n",
      " 169945 62140    0.45981   36   48    0.58995    0.17953  69.6%  56.8  226s\n",
      " 175283 63489     cutoff   53         0.58995    0.18130  69.3%  56.8  231s\n",
      " 179974 65323     cutoff   55         0.58995    0.18298  69.0%  56.9  236s\n",
      " 185284 66677    0.25341   40   46    0.58995    0.18435  68.8%  56.8  241s\n",
      " 190003 67889    0.57227   59   34    0.58995    0.18625  68.5%  56.8  246s\n",
      " 193240 68636    0.20648   46   40    0.58995    0.18788  68.2%  56.8  250s\n",
      " 198411 70560    0.40257   50   42    0.58995    0.18922  68.0%  56.9  255s\n",
      " 203673 72122     cutoff   51         0.58995    0.19096  67.7%  56.8  260s\n",
      " 208707 73503    0.53736   45   39    0.58995    0.19263  67.4%  56.8  265s\n",
      " 213786 74649    0.38070   52   42    0.58995    0.19397  67.2%  56.7  270s\n",
      " 218696 76101    0.33117   53   40    0.58995    0.19577  66.9%  56.7  275s\n",
      " 223452 77417    0.31015   40   45    0.58995    0.19812  66.5%  56.7  280s\n",
      " 228484 78817     cutoff   49         0.58995    0.19943  66.2%  56.7  285s\n",
      " 233218 80341    0.46324   46   44    0.58995    0.20094  66.0%  56.6  290s\n",
      " 238495 82094    0.39338   43   39    0.58995    0.20193  65.8%  56.6  295s\n",
      " 243252 83154    0.42363   44   40    0.58995    0.20303  65.6%  56.6  300s\n",
      " 248231 84224     cutoff   55         0.58995    0.20471  65.4%  56.6  312s\n",
      " 249858 85168    0.23127   49   37    0.58995    0.20512  65.3%  56.6  316s\n",
      " 254868 86595    0.53321   50   38    0.58995    0.20590  65.2%  56.6  321s\n",
      " 258022 87542    0.42974   43   47    0.58995    0.20739  64.9%  56.6  325s\n",
      " 263110 89103     cutoff   52         0.58995    0.20847  64.7%  56.5  330s\n",
      " 266392 90094    0.47620   48   35    0.58995    0.20933  64.6%  56.5  340s\n",
      " 271354 91321    0.32347   47   39    0.58995    0.21145  64.2%  56.6  345s\n",
      " 276278 92543     cutoff   45         0.58995    0.21339  63.9%  56.6  350s\n",
      " 281294 93641    0.58824   53   39    0.58995    0.21439  63.7%  56.6  355s\n",
      " 285979 94745    0.33304   45   38    0.58995    0.21585  63.5%  56.7  360s\n",
      " 290510 95828    0.42808   46   39    0.58995    0.21669  63.3%  56.6  365s\n",
      " 292034 95841    0.45350   51   38    0.58995    0.21704  63.3%  56.6  375s\n",
      " 295345 96855     cutoff   45         0.58995    0.21834  63.0%  56.6  380s\n",
      " 300598 98240     cutoff   50         0.58995    0.22010  62.7%  56.6  385s\n",
      " 305648 99656    0.48804   53   32    0.58995    0.22178  62.5%  56.5  390s\n",
      " 310629 100908    0.24092   51   37    0.58995    0.22283  62.3%  56.5  395s\n",
      " 315455 101868     cutoff   55         0.58995    0.22456  62.0%  56.5  400s\n",
      " 320551 103038     cutoff   56         0.58995    0.22592  61.8%  56.5  405s\n",
      " 325384 103933    0.53201   53   39    0.58995    0.22756  61.5%  56.4  410s\n",
      " 330332 104927     cutoff   49         0.58995    0.22897  61.2%  56.4  415s\n",
      " 334980 105719    0.38630   52   34    0.58995    0.23071  60.9%  56.4  420s\n",
      " 339888 106671     cutoff   52         0.58995    0.23228  60.7%  56.4  425s\n",
      " 344738 107696     cutoff   48         0.58995    0.23399  60.4%  56.4  430s\n",
      " 349558 109050    0.57908   50   40    0.58995    0.23493  60.2%  56.3  435s\n",
      " 354873 110146     cutoff   39         0.58995    0.23643  60.0%  56.3  441s\n",
      " 359726 111197    0.37184   43   41    0.58995    0.23705  59.9%  56.3  446s\n",
      " 363075 111996    0.37108   48   44    0.58995    0.23880  59.6%  56.3  450s\n",
      " 367971 113012     cutoff   52         0.58995    0.23954  59.4%  56.3  455s\n",
      " 372810 114070     cutoff   54         0.58995    0.24140  59.1%  56.3  460s\n",
      " 377889 115162    0.39149   50   40    0.58995    0.24216  59.0%  56.2  465s\n",
      " 382970 116154     cutoff   55         0.58995    0.24371  58.7%  56.2  470s\n",
      " 388042 117559    0.40705   25   48    0.58995    0.24484  58.5%  56.2  475s\n",
      " 392722 118590     cutoff   28         0.58995    0.24557  58.4%  56.2  480s\n",
      " 397732 119834     cutoff   44         0.58995    0.24654  58.3%  56.1  486s\n",
      " 400962 120567    0.56511   44   44    0.58995    0.24659  58.3%  56.1  490s\n",
      " 405875 121460    0.45939   49   44    0.58995    0.24763  58.1%  56.1  496s\n",
      " 410661 122252     cutoff   54         0.58995    0.24942  57.8%  56.1  501s\n",
      " 414012 122954     cutoff   55         0.58995    0.25042  57.6%  56.1  505s\n",
      " 418917 123853    0.41208   50   40    0.58995    0.25174  57.4%  56.1  510s\n",
      " 423616 124709    0.28740   48   36    0.58995    0.25303  57.2%  56.1  515s\n",
      " 428671 125686    0.36938   48   37    0.58995    0.25422  57.0%  56.1  520s\n",
      " 431778 126167    0.32887   58   32    0.58995    0.25505  56.8%  56.1  530s\n",
      " 436829 127195    0.37321   48   44    0.58995    0.25601  56.7%  56.2  535s\n",
      " 442103 128179     cutoff   55         0.58995    0.25748  56.4%  56.2  540s\n",
      " 447024 128927    0.26513   49   39    0.58995    0.25888  56.2%  56.2  545s\n",
      " 451977 129955    0.36079   46   42    0.58995    0.25976  56.0%  56.1  550s\n",
      " 456673 130653    0.50351   42   41    0.58995    0.26094  55.8%  56.1  555s\n",
      " 461378 131371     cutoff   56         0.58995    0.26211  55.6%  56.2  560s\n",
      " 466136 132278    0.55882   43   47    0.58995    0.26336  55.4%  56.2  566s\n",
      " 471065 133138    0.54599   55   33    0.58995    0.26432  55.2%  56.1  570s\n",
      " 476092 134328    0.39849   53   40    0.58995    0.26577  55.0%  56.1  575s\n",
      " 481200 135305     cutoff   48         0.58995    0.26650  54.9%  56.1  580s\n",
      " 486204 136845    0.49422   55   29    0.58995    0.26761  54.7%  56.0  585s\n",
      "H490275 137175                       0.5899451    0.26825  54.6%  56.0  589s\n",
      " 490320 137512    0.58073   54   35    0.58995    0.26825  54.6%  56.0  591s\n",
      " 495700 138335    0.31736   47   37    0.58995    0.26946  54.4%  56.0  596s\n",
      " 499248 138966    0.54302   52   37    0.58995    0.27071  54.2%  56.0  600s\n",
      " 504673 139869     cutoff   40         0.58995    0.27164  54.0%  56.0  605s\n",
      " 509874 140770    0.42421   47   36    0.58995    0.27275  53.8%  55.9  611s\n",
      " 514902 141456     cutoff   47         0.58995    0.27411  53.6%  55.9  616s\n",
      " 519692 142200    0.53203   50   43    0.58995    0.27526  53.4%  55.9  621s\n",
      " 524409 142681    0.46778   52   37    0.58995    0.27651  53.2%  55.9  625s\n",
      " 529453 143381    0.47687   47   49    0.58995    0.27757  53.0%  55.9  630s\n",
      " 534452 143986    0.45784   49   39    0.58995    0.27872  52.8%  55.9  635s\n",
      " 539195 144577    0.38883   49   38    0.58995    0.28006  52.6%  55.8  640s\n",
      " 544081 145285     cutoff   56         0.58995    0.28034  52.5%  55.8  645s\n",
      " 548771 145715     cutoff   58         0.58995    0.28223  52.2%  55.8  650s\n",
      " 553695 146497    0.47236   48   45    0.58995    0.28268  52.1%  55.8  655s\n",
      " 558452 146967     cutoff   49         0.58995    0.28431  51.9%  55.8  660s\n",
      " 563708 147571    0.57104   48   42    0.58995    0.28588  51.6%  55.8  665s\n",
      " 568764 148145    0.40003   48   37    0.58995    0.28714  51.4%  55.8  670s\n",
      " 573684 148891     cutoff   57         0.58995    0.28771  51.3%  55.8  675s\n",
      " 578667 149783    0.34931   54   36    0.58995    0.28886  51.1%  55.8  680s\n",
      " 583202 150380    0.51670   39   40    0.58995    0.29000  50.9%  55.7  685s\n",
      " 588048 150709    0.50912   45   49    0.58995    0.29107  50.7%  55.7  690s\n",
      " 592793 151136    0.41050   50   43    0.58995    0.29231  50.5%  55.7  695s\n",
      " 597804 151850     cutoff   52         0.58995    0.29348  50.3%  55.7  700s\n",
      " 602535 152221    0.52970   52   37    0.58995    0.29480  50.1%  55.7  705s\n",
      " 607482 152751    0.50158   54   36    0.58995    0.29596  49.9%  55.7  710s\n",
      " 612218 153430     cutoff   40         0.58995    0.29700  49.7%  55.6  715s\n",
      " 617442 154193    0.57991   51   32    0.58995    0.29796  49.5%  55.6  720s\n",
      " 622620 154881     cutoff   46         0.58995    0.29908  49.4%  55.6  726s\n",
      " 626053 155394    0.35413   37   52    0.58995    0.29944  49.3%  55.6  730s\n",
      " 631037 155971     cutoff   41         0.58995    0.30002  49.2%  55.6  735s\n",
      " 637581 156489    0.32821   49   39    0.58995    0.30216  48.8%  55.6  741s\n",
      " 642480 157094     cutoff   51         0.58995    0.30344  48.6%  55.6  746s\n",
      " 647463 157866    0.44134   58   30    0.58995    0.30410  48.5%  55.6  751s\n",
      " 652357 158572    0.52796   46   41    0.58995    0.30518  48.3%  55.6  756s\n",
      " 657303 159112    0.47281   50   35    0.58995    0.30613  48.2%  55.6  761s\n",
      " 662229 159424    0.43231   48   40    0.58995    0.30700  48.0%  55.5  765s\n",
      " 666822 159804    0.35283   53   39    0.58995    0.30819  47.8%  55.5  770s\n",
      " 671860 160148    0.34493   45   38    0.58995    0.30921  47.6%  55.5  775s\n",
      " 676839 160637     cutoff   53         0.58995    0.31032  47.4%  55.5  780s\n",
      " 680176 160897    0.58221   53   34    0.58995    0.31081  47.4%  55.5  785s\n",
      " 685078 161156     cutoff   42         0.58995    0.31210  47.1%  55.5  790s\n",
      " 690001 161589     cutoff   45         0.58995    0.31325  47.0%  55.5  796s\n",
      " 693143 161857    0.45348   54   32    0.58995    0.31377  46.9%  55.5  800s\n",
      " 697791 162418     cutoff   38         0.58995    0.31464  46.7%  55.5  805s\n",
      " 702749 162653     cutoff   40         0.58995    0.31552  46.6%  55.5  810s\n",
      " 707665 162958    0.35549   41   39    0.58995    0.31677  46.4%  55.5  815s\n",
      " 712535 163219    0.52584   46   39    0.58995    0.31804  46.1%  55.5  820s\n",
      " 717418 163926     cutoff   60         0.58995    0.31873  46.0%  55.4  825s\n",
      " 722392 164536     cutoff   41         0.58995    0.31951  45.9%  55.4  830s\n",
      " 727176 165240     cutoff   45         0.58995    0.32025  45.8%  55.4  835s\n",
      " 732306 165513     cutoff   42         0.58995    0.32148  45.6%  55.4  847s\n",
      "H732331 165513                       0.5899451    0.32150  45.6%  55.4  847s\n",
      " 732338 165713     cutoff   53         0.58995    0.32154  45.5%  55.4  850s\n",
      "H734001 165768                       0.5899451    0.32179  45.5%  55.4  852s\n",
      " 736158 165900    0.35794   46   45    0.58995    0.32222  45.4%  55.4  855s\n",
      " 740401 166172    0.50120   50   37    0.58995    0.32318  45.3%  55.4  861s\n",
      " 743815 166586    0.44569   53   36    0.58995    0.32387  45.2%  55.4  865s\n",
      " 748758 166976    0.55068   46   39    0.58995    0.32487  45.0%  55.4  870s\n",
      " 755022 167410    0.42866   54   37    0.58995    0.32595  44.8%  55.4  876s\n",
      " 759635 167516    0.46646   50   41    0.58995    0.32692  44.6%  55.4  881s\n",
      " 764686 168054    0.46067   60   34    0.58995    0.32789  44.5%  55.4  886s\n",
      " 768109 168381    0.34211   49   38    0.58995    0.32859  44.4%  55.3  891s\n",
      " 772902 168606     cutoff   46         0.58995    0.32955  44.2%  55.3  896s\n",
      " 777768 168974    0.57506   44   40    0.58995    0.33040  44.0%  55.3  901s\n",
      " 782660 169082    0.38685   52   35    0.58995    0.33134  43.9%  55.3  905s\n",
      " 787547 169572    0.56857   46   36    0.58995    0.33230  43.7%  55.3  911s\n",
      " 790739 169592    0.57238   48   39    0.58995    0.33291  43.6%  55.3  915s\n",
      " 795932 169579     cutoff   44         0.58995    0.33411  43.4%  55.3  921s\n",
      " 799102 169603     cutoff   45         0.58995    0.33499  43.3%  55.3  925s\n",
      " 803903 169773     cutoff   55         0.58995    0.33602  43.1%  55.3  930s\n",
      " 808915 169933    0.44465   47   48    0.58995    0.33666  43.0%  55.3  936s\n",
      " 813739 170124 infeasible   51         0.58995    0.33796  42.8%  55.3  940s\n",
      " 818482 170231    0.52578   57   27    0.58995    0.33898  42.6%  55.3  946s\n",
      " 821776 170172    0.51583   51   37    0.58995    0.33959  42.5%  55.3  950s\n",
      " 826719 170269    0.34908   42   44    0.58995    0.34045  42.3%  55.3  956s\n",
      " 830191 170372     cutoff   59         0.58995    0.34131  42.2%  55.3  960s\n",
      " 834984 170501    0.51876   43   44    0.58995    0.34244  42.0%  55.3  966s\n",
      " 838261 170494    0.48508   54   33    0.58995    0.34301  41.9%  55.3  970s\n",
      " 842797 170339    0.52003   45   36    0.58995    0.34425  41.7%  55.3  976s\n",
      " 847895 170543    0.47475   48   38    0.58995    0.34490  41.6%  55.2  981s\n",
      " 852913 170846    0.40475   45   45    0.58995    0.34567  41.5%  55.2  986s\n",
      " 857569 171001    0.50091   46   39    0.58995    0.34698  41.2%  55.2  991s\n",
      " 862325 171064    0.37638   56   30    0.58995    0.34776  41.1%  55.2  996s\n",
      " 867211 171059    0.35883   46   47    0.58995    0.34874  40.9%  55.2 1000s\n",
      "\n",
      "Cutting planes:\n",
      "  MIR: 4\n",
      "  Flow cover: 8\n",
      "  RLT: 47\n",
      "\n",
      "Explored 867786 nodes (47869582 simplex iterations) in 1000.03 seconds (1293.00 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 10: 0.589946 0.589946 0.590504 ... 0.973812\n",
      "\n",
      "Time limit reached\n",
      "Best objective 5.899450209558e-01, best bound 3.488026386366e-01, gap 40.8754%\n",
      "MILP model status: 9, Model solution count: 10, Final solve time: 1000.035, Final objval : 0.5899\n"
     ]
    }
   ],
   "source": [
    "model_l2 = model\n",
    "\n",
    "expr_qp = QuadExpr()\n",
    "\n",
    "for i in range(num_pixels):\n",
    "    expr_qp.add(\n",
    "        var_list[i] * var_list[i]\n",
    "        - 2 * image_norm[i] * var_list[i]\n",
    "        + image_norm[i] * image_norm[i]\n",
    "    )\n",
    "\n",
    "## Set objective\n",
    "model_l2.setObjective(expr_qp, GRB.MINIMIZE)\n",
    "\n",
    "model_l2.setParam(\"OutputFlag\", 1)\n",
    "model_l2.setParam(\"TimeLimit\", 1000)\n",
    "model_l2.optimize()\n",
    "\n",
    "\n",
    "sol_count = f\"{model_l2.solcount:d}\" if hasattr(model_l2, \"solcount\") else \"None\"\n",
    "obj_bound = f\"{model_l2.objbound:.4f}\" if hasattr(model_l2, \"objbound\") else \"failed\"\n",
    "obj_val = f\"{model_l2.objval:.4f}\" if hasattr(model_l2, \"objval\") else \"failed\"\n",
    "\n",
    "print(\n",
    "    f\"MILP model status: {model_l2.Status}, Model solution count: {sol_count}, Final solve time: {model.Runtime:.3f}, Final objval : {obj_val}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0334cec-ecba-4001-b95f-13076eef70ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model_l2.solcount > 0:\n",
    "    adv_examples_l2 = [model_l2.x[0:num_pixels]]\n",
    "    output_model_l2 = [model_l2.x[counter:num_var]]\n",
    "\n",
    "\n",
    "    if dataset == \"cifar10\":\n",
    "        input_ad = torch.tensor(adv_examples_l2).reshape((3, 32, 32)).type(torch.float)\n",
    "        input_norm = torch.tensor(image_norm).reshape((3, 32, 32)).type(torch.float)\n",
    "        input_ad2 = np.array(adv_examples_l2, dtype=np.float32).reshape([1, 32, 32, 3])\n",
    "        input_norm2 = np.array(image_norm, dtype=np.float32).reshape([1, 32, 32, 3])\n",
    "\n",
    "    if dataset == \"mnist\":\n",
    "        input_ad = torch.tensor(adv_examples_l2).reshape((1, 28, 28)).type(torch.float)\n",
    "        input_norm = torch.tensor(image_norm).reshape((1, 28, 28)).type(torch.float)\n",
    "        input_ad2 = np.array(adv_examples_l2, dtype=np.float32).reshape([1, 28, 28, 1])\n",
    "        input_norm2 = np.array(image_norm, dtype=np.float32).reshape([1, 28, 28, 1])\n",
    "        \n",
    "        \n",
    "    if is_conv:\n",
    "        plot_attack_pred(\n",
    "            torch.from_numpy(input_norm2).permute(0, 3, 1, 2).to(\"cpu\"),\n",
    "            class_names[Image_label],\n",
    "            torch.from_numpy(input_ad2).permute(0, 3, 1, 2).to(\"cpu\"),\n",
    "            class_names[adv_label],\n",
    "        )\n",
    "    else:\n",
    "        plot_attack_pred(\n",
    "            input_norm,\n",
    "            class_names[Image_label],\n",
    "            input_ad,\n",
    "            class_names[adv_label],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f20259-fb0a-44cc-9e39-a4eb105f3802",
   "metadata": {},
   "source": [
    "# The MIP-ReLUplex-gurobi attacks using $L_1$  distance measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e70dd0f-8fec-4e81-bda0-68b68e6c8192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.0 build v9.5.0rc5 (linux64)\n",
      "Thread count: 16 physical cores, 16 logical processors, using up to 16 threads\n",
      "Optimize a model with 2891 rows, 2678 columns and 47868 nonzeros\n",
      "Model fingerprint: 0xc82f0b7c\n",
      "Model has 106 general constraints\n",
      "Variable types: 2572 continuous, 106 integer (106 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-06, 4e+01]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [2e-02, 4e+01]\n",
      "  RHS range        [2e-04, 3e+01]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 9.1976 (0.15s)\n",
      "Loaded MIP start from previous solve with objective 9.1976\n",
      "\n",
      "Presolve removed 2126 rows and 1459 columns\n",
      "Presolve time: 0.17s\n",
      "Presolved: 765 rows, 1219 columns, 40392 nonzeros\n",
      "Variable types: 1114 continuous, 105 integer (105 binary)\n",
      "\n",
      "Root relaxation: objective 0.000000e+00, 240 iterations, 0.02 seconds (0.02 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    0.00000    0    9    9.19760    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   12    9.19760    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   12    9.19760    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0    5    9.19760    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   11    9.19760    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   13    9.19760    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   11    9.19760    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   13    9.19760    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   10    9.19760    0.00000   100%     -    0s\n",
      "     0     0    0.00000    0   10    9.19760    0.00000   100%     -    1s\n",
      "     0     2    0.00000    0   10    9.19760    0.00000   100%     -    1s\n",
      "H  657   436                       9.1936820    0.00000   100%  41.2    3s\n",
      "H 3725  1756                       9.1852626    0.00000   100%  37.6    6s\n",
      "  4249  1998    0.00000   25   29    9.18527    0.00000   100%  39.1   10s\n",
      " 16802  6527     cutoff   36         9.18527    2.02846  78.0%  33.1   15s\n",
      "*18976  7583              73       9.1362018    2.09661  77.1%  32.5   15s\n",
      " 30468 12756     cutoff   56         9.13621    2.88086  68.5%  31.5   20s\n",
      "H42016 16805                       9.0930414    3.34391  63.3%  31.2   32s\n",
      " 42029 16816    3.34391   21   26    9.09305    3.34391  63.3%  31.2   35s\n",
      " 45490 17974    3.34391   45   31    9.09305    3.34391  63.3%  30.5   40s\n",
      " 56197 20231    5.88226   51   36    9.09305    3.34391  63.3%  29.0   45s\n",
      " 72645 21930    5.80507   48   25    9.09305    3.76389  58.7%  28.4   50s\n",
      " 92922 22656     cutoff   74         9.09305    4.52548  50.3%  27.9   55s\n",
      " 109601 27904     cutoff   65         9.09305    4.95281  45.6%  27.6   60s\n",
      " 129048 33399    8.40983   42   35    9.09305    5.31136  41.6%  27.5   65s\n",
      " 148437 38194     cutoff   48         9.09305    5.61867  38.3%  27.4   70s\n",
      " 167996 41889     cutoff   62         9.09305    5.88806  35.3%  27.4   75s\n",
      " 187197 44418    8.66752   64   22    9.09305    6.13830  32.5%  27.4   80s\n",
      " 200391 45647     cutoff   58         9.09305    6.30604  30.7%  27.4   85s\n",
      " 216588 47182     cutoff   55         9.09305    6.48417  28.7%  27.4   90s\n",
      " 231441 47794    8.44243   68   16    9.09305    6.64554  27.0%  27.4   95s\n",
      " 242793 47933    8.87514   66   23    9.09305    6.75910  25.7%  27.4  100s\n",
      " 259491 47342    7.58923   49   33    9.09305    6.95379  23.6%  27.5  105s\n",
      " 277719 46766     cutoff   36         9.09305    7.11969  21.8%  27.4  110s\n",
      " 297158 45943    8.41961   53   27    9.09305    7.27828  20.0%  27.4  115s\n",
      " 316844 44363    8.58981   67   18    9.09305    7.45016  18.1%  27.3  121s\n",
      " 328359 43432     cutoff   65         9.09305    7.53018  17.2%  27.3  125s\n",
      " 346928 40910     cutoff   59         9.09305    7.67354  15.7%  27.3  130s\n",
      " 364691 38373     cutoff   66         9.09305    7.79628  14.3%  27.2  135s\n",
      " 382261 34288    8.71124   55   29    9.09305    7.93826  12.7%  27.2  141s\n",
      " 395706 30062     cutoff   63         9.09305    8.03892  11.6%  27.2  145s\n",
      " 412444 24311    8.22668   55   18    9.09305    8.20554  9.77%  27.1  150s\n",
      " 432463 17220     cutoff   43         9.09305    8.41925  7.42%  27.0  155s\n",
      " 448655 10011     cutoff   53         9.09305    8.61872  5.22%  26.9  160s\n",
      " 461997  3852     cutoff   52         9.09305    8.85116  2.67%  26.9  165s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 22\n",
      "  MIR: 2\n",
      "  Flow cover: 1\n",
      "  RLT: 8\n",
      "\n",
      "Explored 470179 nodes (12597208 simplex iterations) in 166.93 seconds (333.90 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 4: 9.09305 9.13621 9.18527 9.1976 \n",
      "\n",
      "Optimal solution found (tolerance 1.01e-04)\n",
      "Best objective 9.093041303027e+00, best bound 9.093041303027e+00, gap 0.0000%\n",
      "MILP model status: 2, Model solution count: 4, Final solve time: 166.932, Final objval : 9.0930\n"
     ]
    }
   ],
   "source": [
    "model_l1 = model\n",
    "\n",
    "# x_l1_h_grb = m.addVars(attack_np.shape[0], lb=-float('inf'), ub=float('inf'),vtype=GRB.CONTINUOUS, name=f'x_l1_h_grb')\n",
    "# x_l1_v_grb = m.addVars(attack_np.shape[0], lb=-float('inf'), ub=float('inf'),vtype=GRB.CONTINUOUS, name=f'x_l1_v_grb')\n",
    "d_grb = model_l1.addVars(\n",
    "    num_pixels, lb=-eps, ub=eps, vtype=GRB.CONTINUOUS, name=f\"d_grb\"\n",
    ")\n",
    "x_l1_grb = model_l1.addVars(\n",
    "    num_pixels, lb=0, ub=1, vtype=GRB.CONTINUOUS, name=f\"x_l1_grb\"\n",
    ")\n",
    "\n",
    "expr_ln = LinExpr()\n",
    "\n",
    "for i in range(num_pixels):\n",
    "    expr_ln.add(x_l1_grb[i])\n",
    "\n",
    "# Set objective\n",
    "model_l1.setObjective(expr_ln, GRB.MINIMIZE)\n",
    "\n",
    "\n",
    "for i in range(num_pixels):\n",
    "    model_l1.addConstr(d_grb[i] == var_list[i] - image_norm[i], name=f\"c_d_\" + str(i))\n",
    "    model_l1.addConstr(x_l1_grb[i] >= d_grb[i], name=f\"c_x_l1_p_grb_\" + str(i))\n",
    "    model_l1.addConstr(x_l1_grb[i] >= -d_grb[i], name=f\"c_x_l1_n_grb_\" + str(i))\n",
    "\n",
    "model_l1.setParam(\"OutputFlag\", 1)\n",
    "model_l1.setParam(\"TimeLimit\", 1000)\n",
    "model_l1.optimize()\n",
    "\n",
    "sol_count = f\"{model_l1.solcount:d}\" if hasattr(model_l1, \"solcount\") else \"None\"\n",
    "obj_bound = f\"{model_l1.objbound:.4f}\" if hasattr(model_l1, \"objbound\") else \"failed\"\n",
    "obj_val = f\"{model_l1.objval:.4f}\" if hasattr(model_l1, \"objval\") else \"failed\"\n",
    "\n",
    "print(\n",
    "    f\"MILP model status: {model_l1.Status}, Model solution count: {sol_count}, Final solve time: {model_l1.Runtime:.3f}, Final objval : {obj_val}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "464fff88-943b-43e3-bbed-d37a88c65652",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlAAAADTCAYAAABOWS0aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmBUlEQVR4nO3debhcVZnv8d+beR4wkBsQEmToQJOWSRoEGxSIIaKABi6TjBrwXhSv2ECDAmFyuC3gdQCxgaCAgEAjY7eRQUABGVsCwTZMgZBRMpyMkOS9f+x9oOpkrXNqnVNzfT/PkyfJW7v2XlW139qr9l7vXubuAgAAQOl61boBAAAAjYYOFAAAQCI6UAAAAInoQAEAACSiAwUAAJCIDhQAAECipu5Amdk5ZvZv5V62hHW5mW1bjnWVm5mdYGaPVfu5+fO/YmYLzGyFmX2ou+tB4zOz+83s+Bq3IZqntcwTNCYze93MDqh1O0phZtPN7OJqP7eEdb9oZvtVYt2V0DAdqPxL6QUzW2Vm883sSjMb0dlz3P1Sd/9SKetPWbYemNkFZnZDrdtRKjPrK+kySRPdfYi7/63WbUL35QeLhWY2uCD2JTN7uJTnu/tB7n59xRoIBJjZw2a2xMz6d4gXdX7MbFzewe5T/VaWLn89DXPc6oq7/727P1zrdpSqITpQZnaGpO9J+mdJwyXtKWmspBlm1i/ynLre8duZ2VAzG1jrdlTBaEkDJL1Y7hU3ymfdhHpLOr3WjQBKYWbjJH1Ckkv6XG1bU8zMNjUzq3U7kKbuO1BmNkzSNElfdff/cPf33P11SUdIGifp2Hy5C8zsNjO7wcyWSzqh41kaMzvOzN4ws7+Z2bcLf3UULlvw6+N4M5tjZovN7NyC9exhZo+b2VIzm2dmP4515Eqwk6S3zexnZrZnN9dRxMzONrNXzKzNzF4ys8M2XsR+bGbLzOxlM9u/4IHhZnZN/rrmmtnFZta7h+3ZXtJf8v8uNbMH8/jHzeypvB1PmdnHC57T8Rdh6PM52czmSHqwJ+1Dt/1fSd+MnQnu4vN9/5ezmW1rZr/Pl1tsZrcULDfezGaY2Ttm9hczOyLWGDM70cxm5fv9q2Z2SofH/znfr982s5M6PPYhM7vLzJab2Z8kbdPh8Wg7unou6sZxkp6QNF3S+5ePzeyXkraSdLdlwwvOlPRI/vDSPLaXmW1jZg/mx4/FZnZjJ/v+Dmb2mpkdVWLbTpL0mplNM7Otu/n6Orbh15ZdrVlmZo+Y2d93WGRUvk+35fk3tuC5JeddYpsuMLNbzewX+XZfNLPdCx7veEzubNnNzex2M1uUv9dfK0cbU9R9B0rSx5WdubijMOjuKyTdJ+nAgvAhkm6TNELSjYXLm9mOkn4q6RhJY5Sdydqii23vI+nvJO0v6Twz2yGPr5f0fySNkrRX/vj/SntZ77+OxyXtKmmepJvyA8CZZjamO+vLvaLsl9ZwZZ3PGzqs7x/zZUZJOl/SHWa2Sf7YdEnrJG0raRdJEyWVdIrYzP5sZkd3jLv7f0tqT94R7v6pfHv3Svp/kj6k7PLevZY2NmpfSTtI+nTCc1A+T0t6WNI3Oz6Q+PleJOm3kkZK+rCkH+XrGCxphqSbJG0m6UhJP81zOWShpIMlDZN0oqTLzWzXfF2T8nYeKGk7SR3HqvxE0hpl3w0n5X/aX0tX7Yg+F3XlOGXHhRslfdrMRkuSu39R0hxJn82HF3xf0j/lzxmRxx6XZJK+I2lzZd87W0q6oONG8n3uP5X96P9VKQ1z9+8p2682k/S0mT1kZl80s0HdfrXS/cr29c0kPasOx0Rlx8KLlB0Hnm9/vBt59z4z28qyEwtbdbLY5yTdrOw4fZekH6cua2a9JN0t6b+UHcf3l/R1M6vqsaAROlCjJC1293WBx+blj7d73N3vdPcN7r66w7JTJN3t7o+5+7uSzlN2Krcz09x9tbv/l7IP6qOS5O7PuPsT7r4uPxv2M2UH825x99fc/QJlv1xPlTRe0ktmdk8XO2Jsfb9297fz9+EWSX+VtEfBIgslXZGfzbtF2dmhz+RfKJMlfd3dV7r7QkmXK0ugUrb7D+5+U4nN/Iykv7r7L/P38VeSXpb02RKfL0kX5O3s+Fmjes6T9FUz27RDPOXzfU/ZJfnN3X2Nu7cPwD5Y0uvufl2+juck3S7p8FBD3P1ed3/FM79X1in7RP7wEZKuc/eZ7r5SBQc+y86wfkHSefn+NFNS4fisaDtKeC7qgJnto2wfu9Xdn1H2A3KjH3udcffZ7j7D3de6+yJlPwo6fu9/QtmB/jh3vydx/U+4+1eUddCulHSUpLesm8VN7n6tu7e5+1pl+/tHzWx4wSL3uvsj+ePnStrLzLZUYt512OYcdx/h7nM6Wewxd7/P3ddL+qXy42rish+TtKm7X+ju77r7q5J+rhKPVeXSCB2oxcpONYbGuYzJH2/3Zifr2bzwcXdfJamrgczzC/69StIQKbsklXdu5lt2ufBSFXfkgszsE/np4BVmttFYIM9mdn5JWWftLWVnbQZ3XK6E7RxnZs/nvwSWKrtMWNi+uV48i/Qbyt6fsZL6SppX8NyfKfsVUm6b59st9Ia6PitYqLPPG1WQdxjukXR2h4dSPt8zlf26/1N+mr79DM5YSf/Yvi/m++Mxkv5HqC1mdpCZPZFfdliq7MdA+35flP8d2rappD6dPN5ZO7p6LurD8ZJ+6+7tx4ubVHAZrxRmNtrMbrZsaMNySTdo4+/9UyX9sbOB0JZVfLcfB67q+HjeofmzsrNC7yr7/k5iZr3N7LuWDeVYLun1/KHC9hYeD1dIekcfHAdKzrtu6HhcHRA5vne27FhJm3do4znKxtpWTSN0oB6XtFbS5wuDZjZE0kGSHigId3ZGaZ6yywPtzx+o7NJCd1yp7Nf0du4+TNkH1+UAQHd/ND8dPMTd378ebWb9zWyKmd2t7GzRbpK+Jukj7j4rpWH5deyfSzpN0ofcfYSkmR3at4VZ0YDFrSS9rSyh1koalf+KGOHuwwrbWkZvK0uCQltJmpv/e6WkwtPXoeTt6gwiquN8SV9Wceeoq8/3fe4+392/7O6bSzpF2eWCbZXtj78v2BfbL6d8peM6LKuqul3Sv0oane/39+mD/X6esksuhW1pt0jZZevY4521o6vnosby7/ojJO2b/+idr2wIxkfNrP2MRsfvktB3y6V5fEL+vX+sNv7eP1XSVmZ2eaw9nlV8tx8HTi1o54fM7DTLxtE9qKxI45Pu3p2xsUcrG9JygLKhHOPaN1OwzPv7bH483UQfHAdKyrsaelPSax3aONTdJ1ezEXXfgXL3ZcrG8fzIzCaZWV/LqiluVXaW5pclruo2SZ+1bGBrP2WnNLtb9TBU0nJJK8xsvKRu71hm9g/KvtxPl3SnpC3d/Th3f6jDWaKQXmY2oOBPf2VnrFzZF7vM7ERt/AtmM0lfy9/Lw5Vdz7/P3ecpu+zxAzMbZma9LBs42e3Lk524T9L2Zna0mfUxs/8paUdlZzOk7NfXkXkbd1d2CRZ1yN1nS7pFWae/XVef7/vM7HAza/9xs0TZ/rshX3b7fCxI3/zPx+yDsYiF+knqr7xDY2YHKRu/1+5WZYUlO+bjSs4vaP96ZWMsLzCzQflYj8KzE9F2lPBc1N6hysat7ihp5/zPDpIeVTYuSpIWSPpIwXMWKdsHC2NDJa2QtMzMtlBWFd5Rm6RJkv7JzL5bagPN7GRlZ4n2VXa829LdzyrxB3SfDseBvnlb1yq7yjJIWeevo8lmtk9+PLxI0hPu/qbS8q5W/iSpzczOMrOB+Rm3nczsY9VsRN13oCTJs0F95yj7dblc0pPKeqD756c7S1nHi5K+qmxA2jxlibBQ2U6W6pvKevhtys723NL54p1aKGkPd/+Eu1/j7m0Jzz1K0uqCP6+4+0uSfqDszN0CSRMk/aHD855UNrhwsaRLJE3xD+7LdJyyg9FLyg5mtym7VNql/PLLMaUsm2/vYElnKEvyMyUdXHCK/dvKxoQtUfaFUurYKtTGhSq43FzC51voY5KeNLMVysaPnO7ur+a5MFHZuIa3lZ3O/56yjlKRfNmvKesoLVGWn3cVPH6/pCuU/bKfrY0rN09Tdol+vrJCius6rLuzdkSfi7pwvLLxb3Pys53z3X2+sgHJx+SXhL4j6Vv55aBv5kM8LpH0hzy2p7LvoV0lLVNWIHFHaGPuvlRZscJBZnZRiW18XNJYdz/cs7F86xNe35UqPg5cJ+kXyi4lz1X2Xf5E4Hk3Kfsh8Y6yqx7H5u0vOe86smwQ+QrrxtjdFPn7c7CyzvBryo5l/6bsbFvVWNcnOZpTfspyqbLLcK/VuDkAAKCBNMQZqHIxs8/mp9kHKzub9YI+GFwHAABQkpbqQCkbVPd2/mc7SUeWMM4IAACgSMtewgMAAOiuVjsDBQAA0GM96kDltxX4i5nNNrOON9IDWg45ARQjJ9Csun0Jz7IpDP5bWbnmW5KeknRUXkYfew7XC1FX3L1sM6CTE2gG5ET1FN/P+AO1GFqT2pZKt72e3ptYTsRun16KPSTNzuegkZndrGyQdjQxgCZHTgDFypYTsQNqLL5hw4bUTZSsT5/woXPdutCUrXEDBgwIxt99991gPPZaQ9uNLdurV/jCU79+/YLxNWvWJC3/3nvvBeOxzyPWnth7HHtvyiG0zc4+055cwttCxfM/vaW0ecyAZkNOAMXICTStnpyBKomZTZU0tdLbARoFOQEUIyfQiHrSgZqr4gk0P6zwRKFXS7paaq1r22hJ5ARQjJxA0+rJIPI+ygYH7q8sIZ6SdHQ+51zsOSQG6kqZB8ySE2h49ZoTffv2DS4fG3MTGwMUGruzdm14StTUgcz9+4eni4uN2xk0aFAwHrNy5cqk5UNir6l3795J60kd7xUb6xQbGxUbA7V+/cbTBKb2Y1LHsJV9ELm7rzOz0yT9p6Tekq7tLCmAZkdOAMXICTSzqt6JnF/bqDfl/LXdHeQE6k295gRnoDgDJdXXGSjuRA4AAJCIDhQAAEAiOlAAAACJKn4fKAAASmVmwTEqsbEysXFHsXFNoTE05RLbZkzsbt5LliwpR3OCYuOFYuOCYncij4mNpUq9M3xszFvq2KuUdYS2Wak7kQMAALQkOlAAAACJ6EABAAAkogMFAACQiA4UAABAIu5EjpZWr3ddBmqlXnMitdou5S7isXXHpFbbpdwVXYpXysUqwkIVbsOGDQsuu3z58mA89e7csbbH7rpeLqFKuYEDBwaXTb1ze6xCkzuRAwAAlAkdKAAAgER0oAAAABLRgQIAAEhEBwoAACARVXhoafVacQTUSj3kRGg+tdRjVcrcawMGDAjGU+eBi0mpCOxMJSvfUqscayX0WaV+TqmfN1V4AAAAZUIHCgAAIBEdKAAAgER0oAAAABL1aBC5mb0uqU3Seknr3H33LpZvmQGzu+66azB+xx13BOPjxo2rYGvKY+LEicH4rFmzgvE333yzks0pi3IPmCUn4k4++eRgfPTo0cH4pZdeWsnmlMX2228fjJ9yyinB+BlnnFHJ5pRFrXOiV69eHpquo9JThNTC+PHjg/Ff//rXwfiECRNKXnevXuHzIymD67vjU5/6VDD+9NNPB+OxqWXKYejQocF4bGB8bB+L5UR48ps0n3T3xWVYD9AsyAmgGDmBpsMlPAAAgEQ97UC5pN+a2TNmNrUcDQIaHDkBFCMn0JR6eglvH3efa2abSZphZi+7+yOFC+QJQ9KgVZATQDFyAk2pR2eg3H1u/vdCSf8uaY/AMle7++5dDRwEmgE5ARRLzYnYXbuBetPtM1BmNlhSL3dvy/89UdKFZWtZg/v0pz8djMdul98IPve5zwXjJ510UjB+5JFHVrI5dYec6Fys2ubmm2+uckvKZ86cOcF4rNq21XQnJ9w9qVIsNO2LFK9Ce++990ped6VNmjQpGN9kk02C8VB1ohR+D4YPHx5cNvV9WbVqVTAec9hhhwXjJ5xwQjB+3HHHJa0/JDbFzerVq4PxdevW9XibUs8u4Y2W9O/5r4U+km5y9/8oS6uAxkROAMXICTStbneg3P1VSR8tY1uAhkZOAMXICTQzbmMAAACQiA4UAABAIjpQAAAAicoxlUtL69Mn/BZOnjy5yi2pvNhcRt/4xjeC8cGDBwfjK1euLFub0Dhi83s1sjVr1gTjf/jDH6rckuayfv36kpeNfQenrKPSBg4cGIxPmTIlGB80aFAwPmTIkGA8dOuHWLVdTKzCL/b+xrz44ovB+JlnnhmMx+ara2trK3mb5ZonMfRaO6vY4wwUAABAIjpQAAAAiehAAQAAJKIDBQAAkIgOFAAAQCKq8Hrok5/8ZDC+1157BePf//73K9mciorNz7TjjjsG47FKEqrw0CxSK0132WWXYPy5554rW5uagbuXvOzatWuD8VgVWqgiLjYPXKx6LrbN2Hr222+/YHzvvfcOxn/4wx8G47GKsFh1XjnE5iWMvQcDBgwIxrfeeutgPDaXYYpYpWBsYupyzYfIGSgAAIBEdKAAAAAS0YECAABIRAcKAAAgER0oAACARJZS7dDjjZlVb2NlNmHChGD8oYceCsb/9re/BeO77bZbML5ixYruNayKHn744WB8n332CcbHjBkTjC9atKhcTeoxdw+XaVRJI+fE+PHjg/GXX365yi1BOdU6J3r16uWhedli8531798/af2hqrJYdVuski82z14sJ2JzIy5evDgYj1Vxx7Ybeg9Sq9ti70Hs+zpWbTdjxoxgPHac2HTTTYPxJUuWBOOh9yD2WmPvV8o8gRs2bIjmBGegAAAAEtGBAgAASEQHCgAAIBEdKAAAgER0oAAAABJ1OReemV0r6WBJC919pzy2iaRbJI2T9LqkI9w9PGS+SZx77rnBeGwurIMOOigYb4Rqu9icd/vuu28wHpsrqVmRExmq7eJic2TGqnYbXTlzwt2jFXchsTnZ+vXrF4ynzIMWm2MtVvl38cUXB+Ox79RJkyYF48uXLw/GY5VyoePQsGHDktYRqxyPGT58eDAeq7ZbvXp1MD5y5Mik9oTmWE2d2y42x2Hq8bmUM1DTJXX8lM+W9IC7byfpgfz/QKuYLnICKDRd5ARaTJcdKHd/RNI7HcKHSLo+//f1kg4tb7OA+kVOAMXICbSiLi/hRYx293n5v+dLGh1b0MymSpraze0AjYKcAIqRE2hq3e1Avc/dvbO7Kbv71ZKulhr7rstAqcgJoBg5gWbU3Sq8BWY2RpLyvxeWr0lAQyIngGLkBJpad89A3SXpeEnfzf/+TdlaVGNTpkwJxidPnhyMz549Oxh/6qmnytamaotVHMaq7WJz5C1durRMLWoITZsTqZgjr3mr7RKVNSdC8+NJWdVeSKySLzSH25o1a4LLxqq1YtVzEydODMafe+65YLxcx4nQexCrtotVLcYqC2PVc2eddVaJrcvMnDkzGJ87d24wPmLEiGB82bJlG8Vin5NZeFrHclXDd3kGysx+JelxSX9nZm+Z2cnKEuJAM/urpAPy/wMtgZwAipETaEVdnoFy96MiD+1f5rYADYGcAIqRE2hF3IkcAAAgER0oAACARHSgAAAAEvX4PlDN5vDDDw/GQ/PvSNKVV15ZyeZU1Lhx44LxY445Jhhfv359MH7JJZcE46nzE6E+xaphxo4dG4xvvfXWwXgrVeGh+8wsWCmXOpfakiXhafd69dr4vEHv3r2Dy8YqiQ855JBgPFYp+KMf/SgYL5dVq1ZtFItVoMW+x2OViB/5yEeC8ZNOOqnE1mUuvPDCYDxWLRmrIgxVg8faHvtcQ/uAFK5mjFV5SpyBAgAASEYHCgAAIBEdKAAAgER0oAAAABLRgQIAAEjUslV4w4cPD8b33HPPpPX89Kc/LUdzamLq1KnB+KhRo4LxWbNmBeMPPvhg2dqE2jniiCOC8WeffTYYP/TQQ4PxadOmlatJVXfssccG4zfccEOVW9K63D1acRcSq7aLCVVsxeb57NevXzC+xx57lLxuSbruuutKbF33hKrNYnPbtbW1Ja376KOPDsaHDh0ajL/66qvB+H333ReMxyriYp9JSOxziu1HsfcmNk9gDGegAAAAEtGBAgAASEQHCgAAIBEdKAAAgEQtO4g8Nohsiy22CMZvvvnmSjanJrbZZpuk5WfOnFmhlqAebLXVVsF4bLD4o48+WsHW1MacOXOC8QMOOCAYjw10pbCiZ0LTkMSm1IhNWZK6fEifPuFD5LBhw4LxW2+9teR1l1NoP4wNiI69ptjUW9tvv30wHhswH/teiA0Wj03ZEhNqf2w6mNTB4qE2djaYnTNQAAAAiehAAQAAJKIDBQAAkIgOFAAAQCI6UAAAAIm6rMIzs2slHSxpobvvlMcukPRlSYvyxc5x9/B92utU7Hb2zz//fDA+YcKEYHyTTTYJxt95551utasSNttss2B8ypQpSet57LHHytGchtesOfH2228H45/5zGeC8Vgl0qmnnhqMX3XVVd1rWAUceOCBwfj48eOD8bFjxwbjCxYsCMZbrQqvnDlhZtFKsZBY9VjM+vXrS1521apVwfgzzzwTjO+0007BeLmmDokJVRzGpjGJVZXFpjeLVeHG2v7QQw8F46nVdjEp64l91qGpbzpbPqaUM1DTJU0KxC93953zPw11oAB6aLrICaDQdJETaDFddqDc/RFJ9XM6BagxcgIoRk6gFfVkDNRpZvZnM7vWzEaWrUVA4yIngGLkBJpWdztQV0raRtLOkuZJ+kFsQTObamZPm9nT3dwW0AjICaBYt3IidgdxoN50qwPl7gvcfb27b5D0c0l7dLLs1e6+u7vv3t1GAvWOnACKdTcnUqZaAWqpW3PhmdkYd5+X//cwSQ03SVqsQuGVV14Jxr/whS8E4/fee28wftlll3WvYSWIVXrE5raLVRCl/tLjl2FcM+TETTfdFIy/9tprwXhs3sjbbrstGB8wYEAwHptTa/LkycH4wIEDN4q98MILwWXvvPPOYPzcc88NxmMH71jl0pNPPhmMo/s54e7JlXXVtmjRomB87733Dsb/+Mc/BuPf+c53gvHYfhjLldB38y677BJcduTI8JXU2HGls7ngQlIqKGsltdouppTbGPxK0n6SRpnZW5LOl7Sfme0sySW9LumUsrQGaADkBFCMnEAr6rID5e5HBcLXVKAtQEMgJ4Bi5ARaEXciBwAASEQHCgAAIBEdKAAAgERWzcoqM6v7Mq4ddtghGJ82bVowHpsnLDb3UTksXrw4GI99lqNGjQrGU8uFhw4dGozHKhobgbvXtGa6EXIiNmfibrvtFoz/y7/8SyWbo5133nmj2H777Ze0jrlz5wbjseqvWEXgww8/HIzHKhobQa1zonfv3j5o0KCN4itWrEhaz5AhQ4Lx1PWEjBs3Lhj/1re+FYwfdVRoiFi8MrVXr7RzG6HqvNg+HjtOjB49OhiPHSdic+HFjjflEmpP7DX17ds3GI/leejzWLt2rTZs2BB8EzgDBQAAkIgOFAAAQCI6UAAAAInoQAEAACSiAwUAAJCIKrweis03FJuXrhxic43FXH/99cH4Mccck7SeRpjjKFWtK46aMSdicy++8cYbSeuJ7W9XXXXVRrEvfelLSeuePn16MH7CCScE47G5MG+//fak7TaCes2J1LkUY4YPH75RbNmyZUnrSDVhwoRgPHb8iL2m2Bxuofb/7ne/K7F1mSuuuCIYP/3004PxWDVj6P2V0ufUqyexnOAMFAAAQCI6UAAAAInoQAEAACSiAwUAAJCIDhQAAEAiqvBawPnnnx+Mf/vb305aT6xi5IUXXkhuU72o14ojNIbYPIGplbL1hJzoWmyuulilWayidN26dcF4v379gvF333235PbE2hJbd2wOy/POO6/kbUrSdtttF4zPnj07GI+JtTPUZ4nNbVcuVOEBAACUCR0oAACARHSgAAAAEtGBAgAASNRlB8rMtjSzh8zsJTN70cxOz+ObmNkMM/tr/vfIyjcXqD1yAihGTqAVlTK52TpJZ7j7s2Y2VNIzZjZD0gmSHnD375rZ2ZLOlnRW5ZqK7jILF9XE4jGNXG1XZuREi9l2222D8UautiuziudE//79g/FYtVmswjxW+RbSu3fvYDw2J11MyjaleLVdTOg9iFX+xdbdt2/fpG3G1pM652Xq+kNibY99frGqvdTPtcszUO4+z92fzf/dJmmWpC0kHSKpfZba6yUdmrRloEGRE0AxcgKtKGkMlJmNk7SLpCcljXb3eflD8yWNLm/TgPpHTgDFyAm0ilIu4UmSzGyIpNslfd3dlxde/nF3j938zMymSpra04YC9YacAIqRE2glJZ2BMrO+ypLiRne/Iw8vMLMx+eNjJC0MPdfdr3b33d1993I0GKgH5ARQjJxAqymlCs8kXSNplrtfVvDQXZKOz/99vKTflL95QP0hJ4Bi5ARaUSmX8PaW9EVJL5jZ83nsHEnflXSrmZ0s6Q1JR1SkheixWDVKNedBbDLkRIOLVe1MnDgxGJ85c2Ylm9MMypYTZhb8fGIVUqkVbilSq7LqSbkq/1avXh2Mx6r8Uueli1VXrl27NhgfMmTIRrEVK1YkbTP2uQ4ePHijWOz1SyV0oNz9MUmxevf9u3o+0GzICaAYOYFWxJ3IAQAAEtGBAgAASEQHCgAAIBEdKAAAgEQl30gTjWvAgAFJy69Zs6ZCLQHqQ6xS6N577w3Gp02bFoyff/75ZWsTMu6ePBdcyNChQ4Pxtra2ktfRr1+/YHzQoEHB+NKlS4Px2Hdw7HXG5vdLEWt7bJsDBw4MxkOVaZI0f/787jWsg1i1XWyu1pUrV5a87li1bWqlYAxnoAAAABLRgQIAAEhEBwoAACARHSgAAIBEdKAAAAASUYXXAk488cRgPFYxctFFF1WwNUDtff7znw/GY1V411xzTSWbgxJsuummwfiiRYuC8Vi1Xai6q3fv3sFlhw0bFowvWbIkGB85cmTS8jGx9sTmcAtV+aVWUx955JHB+OLFi4Pxiy++OBiPVc+lzr1ajrlaY+9BrEIxpcJP4gwUAABAMjpQAAAAiehAAQAAJKIDBQAAkMjKMVCr5I2ZVW9jeN/dd98djF9++eXB+IMPPljJ5tQVdw+PeKwScgL1ptFyInXAdWgAcWx6k9iULbGpVmLr6dMnXK8VW09sWpVVq1YF46HjeOp0MPfff38w/pOf/CQYv+eee5LWX65pcULTs8SmZunfv38wHps+JiaWE5yBAgAASEQHCgAAIBEdKAAAgER0oAAAABLRgQIAAEjUZRWemW0p6ReSRktySVe7+w/N7AJJX5bUfh/9c9z9vi7WRcUR6kp3Ko7ICTSzesiJUNVa7FgVq7brZP0lrztWORarqhs8eHAwvmLFipLbIknDhw8PxpcvXx6MhyruYpVmscq02GtKrZKLVRDGlk8VqrqMvY/r1q0Lxnv1Cp87ilUuxnKilLnw1kk6w92fNbOhkp4xsxn5Y5e7+7+WsA6gmZATQDFyAi2nyw6Uu8+TNC//d5uZzZK0RaUbBtQrcgIoRk6gFSWNgTKzcZJ2kfRkHjrNzP5sZteaWXAaajObamZPm9nTPWsqUH/ICaAYOYFWUfKdyM1siKTfS7rE3e8ws9GSFiu73n2RpDHuflIX62C8B+pKT+66TE6gGdVDTjAGijFQMfU0BqqkM1Bm1lfS7ZJudPc78hUucPf17r5B0s8l7VHKuoBmQE4AxcgJtJoux0BZ1rW7RtIsd7+sID4mv+4tSYdJmlmZJgL1hZwAipU7J0JnDmJnSFKF1hObSy12piI0H5skLVq0KBgfMWJEMB6bO6+trS0Yj70HofXEzmLFzsqsWbOm5HVL6Wd9YmemVq9eHYzHhLYb22ZMyvvY6XpKWGZvSV+U9IKZPZ/HzpF0lJntrOzU7OuSTknaMtC4yAmgGDmBllNKFd5jkkJdzU7v5QE0K3ICKEZOoBVxJ3IAAIBEdKAAAAAS0YECAABIVJ6yBgAAyiRU/ZZaaRWTct+oWLXdsmXLkrZZrnsgDR06NBgPVbLFKs1iFX4xsfXEPo/YvbNSK9xiQp9J6r4Ra0voHlOd7S+cgQIAAEhEBwoAACARHSgAAIBEdKAAAAAS0YECAABIZLFZqCuyMbNFkt7I/ztK2Szdza5VXqfUeK91rLtvWssGkBNNr9FeKzlRG63yOqXGe63RnKhqB6pow2ZPu/vuNdl4FbXK65Ra67VWQqu8f63yOqXWeq2V0CrvX6u8Tqm5XiuX8AAAABLRgQIAAEhUyw7U1TXcdjW1yuuUWuu1VkKrvH+t8jql1nqtldAq71+rvE6piV5rzcZAAQAANCou4QEAACSqegfKzCaZ2V/MbLaZnV3t7VeSmV1rZgvNbGZBbBMzm2Fmf83/HlnLNpaLmW1pZg+Z2Utm9qKZnZ7Hm/L1VhI50fj7CPlQXuRE4+8nrZATVe1AmVlvST+RdJCkHSUdZWY7VrMNFTZd0qQOsbMlPeDu20l6IP9/M1gn6Qx331HSnpL+d/5ZNuvrrQhyomn2EfKhTMiJptlPmj4nqn0Gag9Js939VXd/V9LNkg6pchsqxt0fkfROh/Ahkq7P/329pEOr2aZKcfd57v5s/u82SbMkbaEmfb0VRE40wT5CPpQVOdEE+0kr5ES1O1BbSHqz4P9v5bFmNtrd5+X/ni9pdC0bUwlmNk7SLpKeVAu83jIjJ5psHyEfeoycaLL9pFlzgkHkVeRZyWNTlT2a2RBJt0v6ursvL3ysGV8vyqvZ9hHyAT3VbPtJM+dEtTtQcyVtWfD/D+exZrbAzMZIUv73whq3p2zMrK+yxLjR3e/Iw037eiuEnGiSfYR8KBtyokn2k2bPiWp3oJ6StJ2ZbW1m/SQdKemuKreh2u6SdHz+7+Ml/aaGbSkbMzNJ10ia5e6XFTzUlK+3gsiJJthHyIeyIieaYD9phZyo+o00zWyypCsk9ZZ0rbtfUtUGVJCZ/UrSfspmm14g6XxJd0q6VdJWymYYP8LdOw4gbDhmto+kRyW9IGlDHj5H2TXupnu9lURONP4+Qj6UFznR+PtJK+QEdyIHAABIxCByAACARHSgAAAAEtGBAgAASEQHCgAAIBEdKAAAgER0oAAAABLRgQIAAEhEBwoAACDR/wfGRkbQyf4otgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model_l1.solcount > 0:\n",
    "    adv_examples_l1 = [model_l1.x[0:num_pixels]]\n",
    "    output_model_l1 = [model_l1.x[counter:num_var]]\n",
    "\n",
    "\n",
    "    if dataset == \"cifar10\":\n",
    "        input_ad = torch.tensor(adv_examples_l1).reshape((3, 32, 32)).type(torch.float)\n",
    "        input_norm = torch.tensor(image_norm).reshape((3, 32, 32)).type(torch.float)\n",
    "        input_ad2 = np.array(adv_examples_l1, dtype=np.float32).reshape([1, 32, 32, 3])\n",
    "        input_norm2 = np.array(image_norm, dtype=np.float32).reshape([1, 32, 32, 3])\n",
    "    if dataset == \"mnist\":\n",
    "        input_ad = torch.tensor(adv_examples_l2).reshape((1, 28, 28)).type(torch.float)\n",
    "        input_norm = torch.tensor(image_norm).reshape((1, 28, 28)).type(torch.float)\n",
    "        input_ad2 = np.array(adv_examples_l2, dtype=np.float32).reshape([1, 28, 28, 1])\n",
    "        input_norm2 = np.array(image_norm, dtype=np.float32).reshape([1, 28, 28, 1])\n",
    "        \n",
    "    if is_conv:\n",
    "        plot_attack_pred(\n",
    "            torch.from_numpy(input_norm2).permute(0, 3, 1, 2).to(\"cpu\"),\n",
    "            class_names[Image_label],\n",
    "            torch.from_numpy(input_ad2).permute(0, 3, 1, 2).to(\"cpu\"),\n",
    "            class_names[adv_label],\n",
    "        )\n",
    "    else:\n",
    "        plot_attack_pred(\n",
    "            input_norm,\n",
    "            class_names[Image_label],\n",
    "            input_ad,\n",
    "            class_names[adv_label],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c934434-2d46-40c3-90bf-6c33e9dbf930",
   "metadata": {},
   "source": [
    "# The MIP-ReLUplex-gurobi attacks using $L_1$  distance measure + TV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9510486d-1162-4437-9719-3139eca65d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.0 build v9.5.0rc5 (linux64)\n",
      "Thread count: 16 physical cores, 16 logical processors, using up to 16 threads\n",
      "Optimize a model with 5969 rows, 4246 columns and 57102 nonzeros\n",
      "Model fingerprint: 0xada80b76\n",
      "Model has 2295 quadratic objective terms\n",
      "Model has 106 general constraints\n",
      "Variable types: 4140 continuous, 106 integer (106 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-06, 4e+01]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  QObjective range [6e+00, 2e+01]\n",
      "  Bounds range     [2e-02, 4e+01]\n",
      "  RHS range        [2e-04, 3e+01]\n",
      "  GenCon coe range [1e+00, 1e+00]\n",
      "\n",
      "MIP start from previous solve produced solution with objective 89.9513 (0.03s)\n",
      "Loaded MIP start from previous solve with objective 89.9513\n",
      "\n",
      "Presolve removed 5204 rows and 3027 columns\n",
      "Presolve time: 0.18s\n",
      "Presolved: 765 rows, 1219 columns, 40392 nonzeros\n",
      "Presolved model has 2295 quadratic objective terms\n",
      "Variable types: 1114 continuous, 105 integer (105 binary)\n",
      "\n",
      "Root relaxation: objective 6.414442e+01, 1573 iterations, 0.07 seconds (0.15 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   64.14442    0   46   89.95122   64.14442  28.7%     -    0s\n",
      "     0     0   64.14442    0   49   89.95122   64.14442  28.7%     -    0s\n",
      "     0     0   64.14442    0   49   89.95122   64.14442  28.7%     -    0s\n",
      "     0     0   64.14442    0   45   89.95122   64.14442  28.7%     -    0s\n",
      "     0     0   64.14442    0   45   89.95122   64.14442  28.7%     -    0s\n",
      "     0     0   64.14442    0   43   89.95122   64.14442  28.7%     -    0s\n",
      "     0     2   64.14442    0   43   89.95122   64.14442  28.7%     -    1s\n",
      "H   80    76                      89.6928448   64.14442  28.5%   127    2s\n",
      "H   81    76                      88.8642244   64.14442  27.9%   125    2s\n",
      "H   86    76                      87.6487375   64.14442  26.9%   120    2s\n",
      "H   95    76                      87.4232425   64.14442  26.7%   111    2s\n",
      "H  672   564                      84.8645887   64.14442  24.5%  35.6    3s\n",
      "H 1040   880                      74.7578412   64.14442  14.2%  33.8    3s\n",
      "H 1141   862                      74.4916617   64.14442  13.9%  34.8    4s\n",
      "  1685   920   70.26453   63   12   74.49167   64.14442  13.9%  33.6    5s\n",
      "H 1712   920                      73.5685944   64.14442  12.9%  33.5    5s\n",
      "  2347  1172   66.02064   33   47   73.56860   64.14442  12.9%  36.3   10s\n",
      "  4292  1516     cutoff   49        73.56860   64.14442  12.9%  41.4   15s\n",
      " 10198  4094   69.12771   50   35   73.56860   65.12442  11.5%  48.0   20s\n",
      " 17774  7613   72.45704   58   24   73.56860   65.78952  10.6%  50.3   25s\n",
      " 26514 11115   73.11426   43   41   73.56860   66.16452  10.1%  50.5   30s\n",
      " 35528 14619   71.91709   48   38   73.56860   66.54809  9.55%  51.2   35s\n",
      " 42878 17542     cutoff   40        73.56860   66.81301  9.19%  51.5   50s\n",
      " 52651 21134   68.49219   55   29   73.56860   67.03085  8.89%  51.6   55s\n",
      " 62389 24223   73.25938   50   39   73.56860   67.23849  8.61%  51.5   60s\n",
      " 70419 26735   68.22446   43   39   73.56860   67.37120  8.43%  51.7   65s\n",
      " 80501 29838   70.79346   41   45   73.56860   67.61852  8.09%  51.5   70s\n",
      " 90008 32882   69.49893   45   38   73.56860   67.80553  7.84%  51.6   75s\n",
      " 99321 35754   69.20766   46   40   73.56860   67.92257  7.68%  51.8   80s\n",
      " 109018 37911   73.05565   45   40   73.56860   68.08157  7.46%  51.9   85s\n",
      " 116700 40035     cutoff   51        73.56860   68.19811  7.30%  52.1   90s\n",
      " 124962 42237   72.91960   41   43   73.56860   68.29965  7.17%  52.1   95s\n",
      " 134745 44590   70.73241   45   38   73.56860   68.42653  6.99%  52.1  100s\n",
      " 136387 44594   69.45507   41   37   73.56860   68.45794  6.95%  52.0  106s\n",
      " 141112 45967   73.32342   44   39   73.56860   68.50714  6.88%  52.1  110s\n",
      " 149256 47755     cutoff   45        73.56860   68.60572  6.75%  52.1  115s\n",
      " 155779 49340     cutoff   57        73.56860   68.68372  6.64%  52.1  120s\n",
      " 165208 51265   72.81407   45   40   73.56860   68.77065  6.53%  52.2  125s\n",
      " 173437 53257     cutoff   36        73.56860   68.84537  6.43%  52.3  130s\n",
      " 181788 55134   72.01077   33   45   73.56860   68.92311  6.32%  52.2  135s\n",
      " 189216 56561     cutoff   52        73.56860   69.00971  6.20%  52.1  140s\n",
      " 198983 58663   72.99689   46   34   73.56860   69.09446  6.09%  52.0  145s\n",
      " 203911 59717   72.21842   43   36   73.56860   69.14204  6.02%  52.0  150s\n",
      " 213867 61705     cutoff   47        73.56860   69.22263  5.91%  52.0  155s\n",
      " 222058 63137   73.45987   51   38   73.56860   69.27531  5.84%  52.0  160s\n",
      " 231653 64903   73.04784   45   38   73.56860   69.34354  5.75%  51.9  165s\n",
      " 239708 66019   73.05370   47   37   73.56860   69.39666  5.68%  51.9  170s\n",
      " 247634 66912     cutoff   39        73.56860   69.47297  5.57%  51.9  175s\n",
      " 257363 68087     cutoff   54        73.56860   69.54663  5.47%  51.9  180s\n",
      " 265283 69018     cutoff   43        73.56860   69.61333  5.38%  51.9  185s\n",
      " 273269 70176   70.56374   43   33   73.56860   69.66144  5.32%  51.9  190s\n",
      " 282992 71369     cutoff   52        73.56860   69.74336  5.20%  51.9  195s\n",
      " 290657 72427     cutoff   48        73.56860   69.80121  5.13%  51.8  200s\n",
      " 297163 73054   71.32973   45   42   73.56860   69.85186  5.06%  51.8  205s\n",
      " 305207 73504     cutoff   56        73.56860   69.90640  4.98%  51.8  210s\n",
      " 311579 73989     cutoff   47        73.56860   69.97463  4.89%  51.8  215s\n",
      " 318180 74197     cutoff   37        73.56860   70.03609  4.81%  51.9  220s\n",
      " 326486 74820   72.59524   53   27   73.56860   70.10723  4.71%  51.8  225s\n",
      " 334393 75160     cutoff   54        73.56860   70.16878  4.63%  51.8  230s\n",
      " 340735 75318   72.27940   55   32   73.56860   70.21785  4.56%  51.8  235s\n",
      " 347108 75478   72.68436   50   37   73.56860   70.27912  4.48%  51.8  240s\n",
      " 355420 75706   72.63196   49   42   73.56860   70.33731  4.40%  51.8  245s\n",
      " 363760 75900   72.71603   50   32   73.56860   70.38980  4.33%  51.8  250s\n",
      " 371740 75814   71.72970   41   44   73.56860   70.45725  4.23%  51.7  255s\n",
      " 379282 76159     cutoff   52        73.56860   70.50935  4.16%  51.7  260s\n",
      " 389363 76340   73.16408   53   33   73.56860   70.57261  4.08%  51.6  265s\n",
      " 397226 75985   72.44066   43   40   73.56860   70.63883  3.99%  51.6  270s\n",
      " 405358 75516   72.99758   48   44   73.56860   70.70243  3.90%  51.6  275s\n",
      " 413870 75142   71.80363   56   28   73.56860   70.76449  3.82%  51.6  280s\n",
      " 421981 74368     cutoff   48        73.56860   70.82724  3.73%  51.6  285s\n",
      " 430042 73503     cutoff   45        73.56860   70.90170  3.63%  51.6  290s\n",
      " 438482 72578   71.50454   40   41   73.56860   70.97259  3.53%  51.6  295s\n",
      " 446961 72142     cutoff   51        73.56860   71.02655  3.46%  51.5  300s\n",
      " 453340 71741   71.31924   31   37   73.56860   71.07581  3.39%  51.5  308s\n",
      " 454902 71451   72.84546   43   42   73.56860   71.08828  3.38%  51.5  310s\n",
      " 463712 70805   73.18755   54   34   73.56860   71.15355  3.29%  51.5  315s\n",
      " 472253 69827     cutoff   43        73.56860   71.20752  3.21%  51.4  320s\n",
      " 480338 68371   72.64347   58   31   73.56860   71.27656  3.12%  51.4  325s\n",
      " 488726 67052     cutoff   52        73.56860   71.34542  3.03%  51.4  330s\n",
      " 498511 65158   72.89953   49   33   73.56860   71.42803  2.91%  51.4  335s\n",
      " 505583 64118   72.45534   52   32   73.56860   71.47549  2.85%  51.3  340s\n",
      " 514015 63339     cutoff   53        73.56860   71.52916  2.78%  51.3  345s\n",
      " 522336 61568   72.59209   41   47   73.56860   71.59483  2.69%  51.2  350s\n",
      " 530736 59475     cutoff   50        73.56860   71.66546  2.59%  51.2  355s\n",
      " 539311 57650     cutoff   43        73.56860   71.73264  2.50%  51.1  360s\n",
      " 549006 55226     cutoff   63        73.56860   71.80773  2.40%  51.1  365s\n",
      " 557442 52974     cutoff   40        73.56860   71.87771  2.30%  51.0  370s\n",
      " 566101 50916     cutoff   47        73.56860   71.94725  2.21%  51.0  375s\n",
      " 571221 49767     cutoff   50        73.56860   71.98280  2.16%  50.9  380s\n",
      " 579881 48165   72.04560   32   33   73.56860   72.02292  2.11%  50.8  385s\n",
      " 587929 45568   73.30255   46   39   73.56860   72.11331  1.98%  50.8  390s\n",
      " 598346 42072     cutoff   63        73.56860   72.20566  1.86%  50.7  395s\n",
      " 608453 38525   72.73932   46   33   73.56860   72.31797  1.70%  50.6  400s\n",
      " 616971 35416     cutoff   54        73.56860   72.39988  1.59%  50.5  405s\n",
      " 627322 31319     cutoff   38        73.56860   72.52260  1.43%  50.4  410s\n",
      " 636617 27092     cutoff   43        73.56860   72.64160  1.27%  50.2  415s\n",
      " 645400 24186     cutoff   46        73.56860   72.72311  1.15%  50.1  420s\n",
      " 655841 20032     cutoff   35        73.56860   72.86277  0.96%  49.9  425s\n",
      " 667720 13608   73.10701   44   41   73.56860   73.10669  0.63%  49.6  430s\n",
      " 677080  6078     cutoff   49        73.56860   73.24800  0.44%  49.6  435s\n",
      " 689100    42     cutoff   56        73.56860   73.46140  0.15%  49.3  440s\n",
      "\n",
      "Cutting planes:\n",
      "  MIR: 5\n",
      "  Flow cover: 8\n",
      "  RLT: 39\n",
      "\n",
      "Explored 690458 nodes (33983742 simplex iterations) in 440.73 seconds (988.37 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 3: 73.5686 74.7579 87.4233 \n",
      "\n",
      "Optimal solution found (tolerance 1.01e-04)\n",
      "Best objective 7.356859434668e+01, best bound 7.356859434667e+01, gap 0.0000%\n",
      "MILP model status: 2, Model solution count: 3, Final solve time: 440.726, Final objval : 73.5686\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if dataset == \"cifar10\":\n",
    "    ff = 32\n",
    "    clr = 3\n",
    "if dataset == \"mnist\":\n",
    "    ff = 28\n",
    "    clr = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f_carre = ff * ff\n",
    "par_lamda = 1.5\n",
    "\n",
    "\n",
    "model_l1_tv = model_l1\n",
    "\n",
    "# d_grb      = model_l1.addVars(num_pixels, lb = 0, ub = float('inf'), vtype = GRB.CONTINUOUS, name = f'd_grb')\n",
    "# x_l1_grb   = model_l1.addVars(num_pixels, lb = 0, ub = float('inf'), vtype = GRB.CONTINUOUS, name = f'x_l1_grb')\n",
    "x_l1_h_grb = model_l1_tv.addVars(\n",
    "    num_pixels, lb=0, ub=float(\"inf\"), vtype=GRB.CONTINUOUS, name=f\"x_l1_h_grb\"\n",
    ")\n",
    "x_l1_v_grb = model_l1_tv.addVars(\n",
    "    num_pixels, lb=0, ub=float(\"inf\"), vtype=GRB.CONTINUOUS, name=f\"x_l1_v_grb\"\n",
    ")\n",
    "\n",
    "expr_qp = QuadExpr()\n",
    "\n",
    "for i in range(num_pixels):\n",
    "    expr_qp.add(x_l1_grb[i])\n",
    "\n",
    "for i in range(0, clr * f_carre - 1):\n",
    "    if i % (ff - 1) > 0 or i == 0:\n",
    "        expr_qp.add(\n",
    "            par_lamda * var_list[i + 1] * var_list[i + 1]\n",
    "            - 2 * par_lamda * var_list[i + 1] * var_list[i]\n",
    "            + par_lamda * var_list[i] * var_list[i]\n",
    "        )\n",
    "for c in range(clr):\n",
    "    for i in range(c * f_carre, (c + 1) * f_carre - ff):\n",
    "        expr_qp.add(\n",
    "            par_lamda * var_list[i + ff] * var_list[i + ff]\n",
    "            - 2 * par_lamda * var_list[i + ff] * var_list[i]\n",
    "            + par_lamda * var_list[i] * var_list[i]\n",
    "        )\n",
    "\n",
    "\n",
    "# Set objective\n",
    "model_l1_tv.setObjective(expr_qp, GRB.MINIMIZE)\n",
    "\n",
    "for i in range(num_pixels - 1):\n",
    "    model_l1_tv.addConstr(\n",
    "        x_l1_h_grb[i] >= d_grb[i] - d_grb[i + 1], name=f\"c_x_l1_h_p_grb_\" + str(i)\n",
    "    )\n",
    "    model_l1_tv.addConstr(\n",
    "        x_l1_h_grb[i] >= -d_grb[i] + d_grb[i + 1], name=f\"c_x_l1_h_n_grb_\" + str(i)\n",
    "    )\n",
    "\n",
    "for i in range(num_pixels - ff):\n",
    "    model_l1_tv.addConstr(\n",
    "        x_l1_v_grb[i] >= d_grb[i] - d_grb[i + ff], name=f\"c_x_l1_v_p_grb\" + str(i)\n",
    "    )\n",
    "    model_l1_tv.addConstr(\n",
    "        x_l1_v_grb[i] >= -d_grb[i] + d_grb[i + ff], name=f\"c_x_l1_v_n_grb\" + str(i)\n",
    "    )\n",
    "\n",
    "\n",
    "model_l1_tv.setParam(\"OutputFlag\", 1)\n",
    "model_l1_tv.setParam(\"TimeLimit\", 1000)\n",
    "model_l1_tv.optimize()\n",
    "\n",
    "sol_count = f\"{model_l1_tv.solcount:d}\" if hasattr(model_l1_tv, \"solcount\") else \"None\"\n",
    "obj_bound = (\n",
    "    f\"{model_l1_tv.objbound:.4f}\" if hasattr(model_l1_tv, \"objbound\") else \"failed\"\n",
    ")\n",
    "obj_val = f\"{model_l1_tv.objval:.4f}\" if hasattr(model_l1_tv, \"objval\") else \"failed\"\n",
    "\n",
    "print(\n",
    "    f\"MILP model status: {model_l1_tv.Status}, Model solution count: {sol_count}, Final solve time: {model_l1_tv.Runtime:.3f}, Final objval : {obj_val}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ded1cc-a627-4b0e-9906-aa23ac14f43e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "9\n",
      "[[0.08932019152364241, 0.0, 0.0, 0.0, 6.576124609042237, 0.0, 0.0, 2.4690095788205566, 0.0, 6.676124609042237]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model_l1_tv.solcount > 0:\n",
    "    adv_examples_l1_tv = [model_l1_tv.x[0:num_pixels]]\n",
    "    output_model_l1_tv = [model_l1_tv.x[counter:num_var]]\n",
    "\n",
    "\n",
    "    if dataset == \"cifar10\":\n",
    "        input_ad = torch.tensor(adv_examples_l1_tv).reshape((3, 32, 32)).type(torch.float)\n",
    "        input_norm = torch.tensor(image_norm).reshape((3, 32, 32)).type(torch.float)\n",
    "        input_ad2 = np.array(adv_examples_l1_tv, dtype=np.float32).reshape([1, 32, 32, 3])\n",
    "        input_norm2 = np.array(image_norm, dtype=np.float32).reshape([1, 32, 32, 3])\n",
    "\n",
    "\n",
    "    if is_conv:\n",
    "        plot_attack_pred(\n",
    "            torch.from_numpy(input_norm2).permute(0, 3, 1, 2).to(\"cpu\"),\n",
    "            class_names[Image_label],\n",
    "            torch.from_numpy(input_ad2).permute(0, 3, 1, 2).to(\"cpu\"),\n",
    "            class_names[adv_label],\n",
    "        )\n",
    "    else:\n",
    "        plot_attack_pred(\n",
    "            input_norm,\n",
    "            class_names[Image_label],\n",
    "            input_ad,\n",
    "            class_names[adv_label],\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384.485px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
