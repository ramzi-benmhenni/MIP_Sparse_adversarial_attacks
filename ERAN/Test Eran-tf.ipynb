{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4970d171",
   "metadata": {},
   "source": [
    "## Ceci est un Test pour Trduire ONNX to MIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18443f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 09:43:44.858083: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/gurobi952/linux64/lib\n",
      "2023-01-18 09:43:44.858140: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ramzi.ben-mhenni/venvpython3.7/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-18 09:43:46.604242: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-18 09:43:46.606883: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/gurobi952/linux64/lib\n",
      "2023-01-18 09:43:46.606930: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-18 09:43:46.606971: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (calcul-02): /proc/driver/nvidia/version does not exist\n",
      "/home/ramzi.ben-mhenni/eran/tf_verify/optimizer.py:26: UserWarning: gpupoly not available.\n",
      "  warnings.warn(\"gpupoly not available.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "sys.path.insert(0, '../ELINA/python_interface/')\n",
    "\n",
    "from tensorflow_translator import *\n",
    "from onnx_translator import *\n",
    "from read_net_file   import *\n",
    "\n",
    "from analyzer  import *\n",
    "from optimizer import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426807b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "if dataset in ['mnist', 'fashion']:\n",
    "    height, width, channels = 28, 28, 1\n",
    "else:\n",
    "    height, width, channels = 32, 32, 3\n",
    "\n",
    "num_pixels = height * width * channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de92a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU\n",
      "\tOutShape:  (1, 100)\n",
      "\tWShape:  (3072, 100)\n",
      "\tBShape:  (100,)\n",
      "ReLU\n",
      "\tOutShape:  (1, 100)\n",
      "\tWShape:  (100, 100)\n",
      "\tBShape:  (100,)\n",
      "ReLU\n",
      "\tOutShape:  (1, 100)\n",
      "\tWShape:  (100, 100)\n",
      "\tBShape:  (100,)\n",
      "ReLU\n",
      "\tOutShape:  (1, 100)\n",
      "\tWShape:  (100, 100)\n",
      "\tBShape:  (100,)\n",
      "ReLU\n",
      "\tOutShape:  (1, 10)\n",
      "\tWShape:  (100, 10)\n",
      "\tBShape:  (10,)\n",
      "WARNING:tensorflow:From /home/ramzi.ben-mhenni/eran/tf_verify/tensorflow_translator.py:127: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/ramzi.ben-mhenni/venvpython3.7/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py:925: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "WARNING:tensorflow:From /home/ramzi.ben-mhenni/eran/tf_verify/tensorflow_translator.py:128: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.remove_training_nodes`\n"
     ]
    }
   ],
   "source": [
    "is_onnx = False\n",
    "is_trained_with_pytorch = False\n",
    "is_gpupoly = False\n",
    "\n",
    "\n",
    "if is_onnx:\n",
    "    net_file = \"cifar_mlp.onnx\"\n",
    "    model, is_conv = read_onnx_net(net_file)\n",
    "    translator = ONNXTranslator(model, True)\n",
    "else:\n",
    "    net_file =\"/home/ramzi.ben-mhenni/eran/data/model/convSmallRELU__Point.pyt\"\n",
    "    net_file =\"/home/ramzi.ben-mhenni/eran/data/model/cifar_relu_6_100.tf\"\n",
    "    net_file =\"/home/ramzi.ben-mhenni/eran/data/model/cifar_relu_4_100.tf\"    \n",
    "    \n",
    "    model, is_conv, mean, std = read_tensorflow_net(net_file, num_pixels, is_trained_with_pytorch, is_gpupoly)\n",
    "    translator = TFTranslator(model, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "632d3190",
   "metadata": {},
   "outputs": [],
   "source": [
    "operations, resources = translator.translate()\n",
    "optimizer = Optimizer(operations, resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b02edcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image_label : \n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramzi.ben-mhenni/venvpython3.7/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "filename = '../data/'+ dataset+ '_test.csv'\n",
    "csvfile = open(filename, 'r')\n",
    "tests = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "test = next(tests)\n",
    "test = next(tests)\n",
    "test = next(tests)\n",
    "\n",
    "image = torch.from_numpy(np.float64(test[1:len(test)]) / np.float64(255)).reshape(1, height, width, channels).permute(0, 3, 1, 2).to('cpu')\n",
    "#image = torch.from_numpy(np.float64(test[1:len(test)]) / np.float64(255))\n",
    "\n",
    "\n",
    "#input_v = np.array(test_input, dtype=np.float32).reshape([1, 32, 32, 3])\n",
    "image_v = image.clone().permute(0, 2, 3, 1).flatten().cpu()\n",
    "#image_v = image.clone().flatten().cpu()\n",
    "\n",
    "label = np.int(test[0])\n",
    "\n",
    "# Printing output\n",
    "print(\"Image_label : \")\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f906a3b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "def imshow(img, fig):\n",
    "    img = img \n",
    "    npimg = img.numpy()\n",
    "    fig.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    \n",
    "def plot_attack_pred(original, attack):\n",
    "    # show image and noise\n",
    "    ax, fig = plt.subplots(nrows=1,ncols=2, figsize=(10,8))\n",
    "    fig[0].set_title(\"Attack\")\n",
    "    imshow(torchvision.utils.make_grid(attack), fig[0])\n",
    "    noise = (original - attack).detach()\n",
    "    fig[1].set_title(\"Noise added to original image\")\n",
    "    imshow(10*torchvision.utils.make_grid(noise), fig[1])\n",
    "    plt.show()\n",
    "\n",
    "def plot_image_pred(img,name):\n",
    "    # show image and noise\n",
    "    ax, fig = plt.subplots(nrows=1,ncols=2, figsize=(10,8))\n",
    "    fig[0].set_title(\"Original\")\n",
    "    plt.xlabel(name)\n",
    "    imshow(torchvision.utils.make_grid(img), fig[0])\n",
    "    noise = (img - img + 1).detach()\n",
    "    fig[1].set_title(\"No Noise\")\n",
    "    imshow(10*torchvision.utils.make_grid(noise), fig[1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_image_pred(image,class_names[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78c12255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(base, input):\n",
    "    if is_onnx:\n",
    "        pred = base.run(input)\n",
    "    else:\n",
    "        pred = base.run(base.graph.get_operation_by_name(model.op.name).outputs[0], {base.graph.get_operations()[0].name + ':0': input})\n",
    "    return pred\n",
    "\n",
    "sess = tf.Session()\n",
    "#sess = None\n",
    "# refactor this out of this method\n",
    "if is_onnx:\n",
    "    runnable = rt.prepare(model, 'CPU')\n",
    "elif sess is None:\n",
    "    config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "    runnable = tf.Session(config=config)\n",
    "else:\n",
    "    runnable = sess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1bca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50.50049533  1.64337118  9.46747401  0.          0.          0.\n",
      "   0.          0.         41.51733587  5.37219362]]\n"
     ]
    }
   ],
   "source": [
    "image_vv = np.array(image_v, dtype=np.double)\n",
    "pred = model_predict(runnable, image_vv)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5faf497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image, means, stds, dataset):\n",
    "    # normalization taken out of the network\n",
    "    if len(means) == len(image):\n",
    "        for i in range(len(image)):\n",
    "            image[i] -= means[i]\n",
    "            if stds!=None:\n",
    "                image[i] /= stds[i]\n",
    "    elif dataset == 'mnist'  or dataset == 'fashion':\n",
    "        for i in range(len(image)):\n",
    "            image[i] = (image[i] - means[0])/stds[0]\n",
    "    elif(dataset=='cifar10'):\n",
    "        count = 0\n",
    "        tmp = np.zeros(3072)\n",
    "        for i in range(1024):\n",
    "            tmp[count] = (image[count] - means[0])/stds[0]\n",
    "            count = count + 1\n",
    "            tmp[count] = (image[count] - means[1])/stds[1]\n",
    "            count = count + 1\n",
    "            tmp[count] = (image[count] - means[2])/stds[2]\n",
    "            count = count + 1\n",
    "\n",
    "        \n",
    "        is_gpupoly = False\n",
    "        if is_conv and not is_gpupoly:\n",
    "            for i in range(3072):\n",
    "                image[i] = tmp[i]\n",
    "            #for i in range(1024):\n",
    "            #    image[i*3] = tmp[i]\n",
    "            #    image[i*3+1] = tmp[i+1024]\n",
    "            #    image[i*3+2] = tmp[i+2048]\n",
    "        else:\n",
    "            count = 0\n",
    "            for i in range(1024):\n",
    "                image[i] = tmp[count]\n",
    "                count = count+1\n",
    "                image[i+1024] = tmp[count]\n",
    "                count = count+1\n",
    "                image[i+2048] = tmp[count]\n",
    "                count = count+1\n",
    "\n",
    "                \n",
    "means = [0.5, 0.5, 0.5]\n",
    "stds = [1, 1, 1]\n",
    "normalize(image_v, means, stds, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86703058",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_trained_with_pytorch:\n",
    "    if dataset == 'mnist' and not config.geometric:\n",
    "        means = [0]\n",
    "        stds = [1]\n",
    "    elif dataset == 'acasxu':\n",
    "\n",
    "    elif dataset == \"cifar10\":\n",
    "        means = [0.4914, 0.4822, 0.4465]\n",
    "        stds = [0.2023, 0.1994, 0.2010]\n",
    "    else:\n",
    "        means = [0.5, 0.5, 0.5]\n",
    "        stds = [1, 1, 1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b98c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_predict(runnable, image_v)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cf20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_flows =  2* num_pixels\n",
    "delta = 0.02\n",
    "\n",
    "\n",
    "specLB = image.clone().permute(0, 2, 3, 1).flatten().cpu() -delta\n",
    "specUB = image.clone().permute(0, 2, 3, 1).flatten().cpu() +delta\n",
    "\n",
    "flows_LB = torch.full((num_flows,), -delta).to('cpu')\n",
    "flows_UB = torch.full((num_flows,), delta).to('cpu')\n",
    "\n",
    "speLB = torch.cat((specLB, flows_LB))\n",
    "speUB = torch.cat((specUB, flows_UB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0561bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deepzono\n",
    "# execute_list_deepzono, output_info_deepzono = optimizer.get_deepzono(nn, specLB , specUB )\n",
    "# use_dict =  optimizer.deepzono_get_dict(execute_list_deepzono)\n",
    "\n",
    "nn = layers()\n",
    "\n",
    "#deeppoly\n",
    "lexpr_weights= None\n",
    "lexpr_cst=None\n",
    "lexpr_dim=None\n",
    "uexpr_weights=None\n",
    "uexpr_cst=None\n",
    "uexpr_dim=None\n",
    "expr_size=0\n",
    "\n",
    "domain = 'deeppoly'\n",
    "timeout_lp = 100\n",
    "timeout_milp = 100\n",
    "timeout_final_lp=100\n",
    "timeout_final_milp=100\n",
    "\n",
    "use_default_heuristic = True\n",
    "output_constraints = False\n",
    "\n",
    "testing = False\n",
    "label= 8\n",
    "prop = 1\n",
    "spatial_constraints=None\n",
    "K=0\n",
    "s=0\n",
    "\n",
    "max_milp_neurons=10000\n",
    "approx_k=False\n",
    "\n",
    "execute_list_deeppoly, output_info_deeppoly =optimizer.get_deeppoly(nn, specLB, specUB, lexpr_weights, lexpr_cst, lexpr_dim, uexpr_weights, uexpr_cst, uexpr_dim, expr_size, spatial_constraints=None)\n",
    "\n",
    "output_info_deeppoly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f26d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abstractBigM(nn,ir_list,timeout_lp,timeout_milp):\n",
    "        \"\"\"\n",
    "        processes self.ir_list and returns the resulting abstract element\n",
    "        \"\"\"\n",
    "        man = fppoly_manager_alloc()\n",
    "        element = ir_list[0].transformer(man)\n",
    "        nlb = [0]\n",
    "        nub = [0]\n",
    "        testing_nlb = []\n",
    "        testing_nub = []\n",
    "        \n",
    "        domain = 'deeppoly'\n",
    "        \n",
    "        relu_groups = False\n",
    "        use_default_heuristic = True\n",
    "        testing = True\n",
    "        \n",
    "        \n",
    "        for i in range(1, len(ir_list)):\n",
    "            if type(ir_list[i]) in [DeeppolyReluNode,DeeppolySigmoidNode,DeeppolyTanhNode,DeepzonoRelu,DeepzonoSigmoid,DeepzonoTanh]:\n",
    "                element_test_bounds = ir_list[i].transformer(nn, man, element, nlb, nub,\n",
    "                                                                  relu_groups, 'refine' in domain,\n",
    "                                                                  timeout_lp, timeout_milp,\n",
    "                                                                  use_default_heuristic, testing,\n",
    "                                                                  K=1, s=1, use_milp=True,\n",
    "                                                                  approx=0)\n",
    "                print(\"1 :\")\n",
    "                \n",
    "            else:\n",
    "                element_test_bounds = ir_list[i].transformer(nn, man, element, nlb, nub,\n",
    "                                                                  relu_groups, 'refine' in domain,\n",
    "                                                                  timeout_lp, timeout_milp,\n",
    "                                                                  use_default_heuristic, testing)\n",
    "                print(\"2 :\")\n",
    "                \n",
    "\n",
    "            if testing and isinstance(element_test_bounds, tuple):\n",
    "                element, test_lb, test_ub = element_test_bounds\n",
    "                testing_nlb.append(test_lb)\n",
    "                testing_nub.append(test_ub)\n",
    "            else:\n",
    "                element = element_test_bounds\n",
    "        if domain in [\"refinezono\", \"refinepoly\"]:\n",
    "            gc.collect()\n",
    "        if testing:\n",
    "            return element, testing_nlb, testing_nub\n",
    "        return element, nlb, nub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58118dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout_lp = 100\n",
    "timeout_milp = 100\n",
    "element, nlb, nub = get_abstractBigM(nn,execute_list_deeppoly,timeout_lp,timeout_milp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea760eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This network has ' + str(optimizer.get_neuron_count()) + ' neurons.')\n",
    "\n",
    "for i in range(nn.numlayer):\n",
    "    print(nn.layertypes[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#execute_list = execute_list_deeppoly\n",
    "#analyzer = Analyzer(execute_list, nn, domain, timeout_lp, timeout_milp, output_constraints,\n",
    "#                                use_default_heuristic, label, prop, testing, K=K, s=s,\n",
    "#                                timeout_final_lp=timeout_final_lp, timeout_final_milp=timeout_final_milp,\n",
    "#                                use_milp=use_milp, complete=complete,\n",
    "#                                partial_milp=partial_milp, max_milp_neurons=max_milp_neurons)\n",
    "#terminate_on_failure= True\n",
    "#dominant_class, nlb, nub, failed_labels, x = analyzer.analyze(terminate_on_failure=terminate_on_failure)\n",
    "\n",
    "    \n",
    "#print(failed_labels)\n",
    "#print(x)\n",
    "#print(dominant_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06173ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#milp_activation_layers = np.nonzero([l in [\"ReLU\", \"Maxpool\"] for l in nn.layertypes])[0]\n",
    "#partial_milp = 0\n",
    "#### Determine whcich layers, if any to encode with MILP\n",
    "#if partial_milp < 0:\n",
    "#    partial_milp = len(milp_activation_layers)\n",
    "#first_milp_layer = len(nn.layertypes) if partial_milp == 0 else milp_activation_layers[-min(partial_milp, len(milp_activation_layers))]\n",
    "\n",
    "#first_milp_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62beaadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "relu_groups = None\n",
    "use_milp=True\n",
    "complete=True\n",
    "partial_milp=False\n",
    "is_nchw=False\n",
    "partial_milp=2\n",
    "max_milp_neurons = 1000\n",
    "\n",
    "counter, var_list, model = create_model(nn, specLB, specUB, nlb, nub, relu_groups, nn.numlayer, use_milp, is_nchw, partial_milp, max_milp_neurons)\n",
    "\n",
    "num_var = len(var_list)\n",
    "output_size = num_var - counter\n",
    "#model.write(\"model_refinepoly.lp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7513692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_label = 5\n",
    "\n",
    "obj = LinExpr()\n",
    "obj += 1 * var_list[counter + label]\n",
    "obj += -1 * var_list[counter + adv_label]\n",
    "model.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + label] )\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + 0] )\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + 1] )\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + 2] )\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + 3] )\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + 4] )\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + 5] )\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + 6] )\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + 7] )\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + 8] )\n",
    "#model.addConstr( var_list[counter + adv_label] >= var_list[counter + 9] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e129fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#expr_qp= QuadExpr()\n",
    "\n",
    "#for i in range(num_pixels):\n",
    "#    expr_qp.add(var_list[i] * var_list[i] - 2*image_v[i] * var_list[i] + image_v[i]*image_v[i]) \n",
    "\n",
    "## Set objective\n",
    "#model.setObjective(expr_qp, GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88466561",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setParam(\"OutputFlag\",1)\n",
    "model.setParam(\"TimeLimit\", 100)\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd04668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_count = f\"{model.solcount:d}\" if hasattr(model, \"solcount\") else \"None\"\n",
    "obj_bound = f\"{model.objbound:.4f}\" if hasattr(model, \"objbound\") else \"failed\"\n",
    "obj_val = f\"{model.objval:.4f}\" if hasattr(model, \"objval\") else \"failed\"     \n",
    "\n",
    "print(f\"MILP model status: {model.Status}, Model solution count: {sol_count}, Final solve time: {model.Runtime:.3f}, Final objval : {obj_val} \")\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model.solcount > 0:\n",
    "    adv_examples = [model.x[0:num_pixels]]\n",
    "    output_model = [model.x[counter:num_var]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label)\n",
    "print(adv_label)\n",
    "print(output_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_examples_img = torch.from_numpy(np.float64(adv_examples)).reshape(1, height, width, channels).permute(0, 3, 1, 2).to('cpu')\n",
    "plot_attack_pred(image, adv_examples_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image- adv_examples_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fe883f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132d7ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
