{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb1e42b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  Copyright 2020 ETH Zurich, Secure, Reliable, and Intelligent Systems Lab\n",
    "\n",
    "  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "  you may not use this file except in compliance with the License.\n",
    "  You may obtain a copy of the License at\n",
    "\n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "  Unless required by applicable law or agreed to in writing, software\n",
    "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "  See the License for the specific language governing permissions and\n",
    "  limitations under the License.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gurobipy import *\n",
    "from fconv import *\n",
    "import numpy as np\n",
    "from config import config\n",
    "import multiprocessing\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e9a883",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def milp_callback(model, where):\n",
    "    if where == GRB.Callback.MIP:\n",
    "        obj_best = model.cbGet(GRB.Callback.MIP_OBJBST)\n",
    "        obj_bound = model.cbGet(GRB.Callback.MIP_OBJBND)\n",
    "        if obj_bound > 0.01:\n",
    "            model.terminate()\n",
    "        if obj_best < -0.01:\n",
    "            model.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84be146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_callback(model, where):\n",
    "    # pass\n",
    "    if where == GRB.Callback.SIMPLEX:\n",
    "        obj_best = model.cbGet(GRB.Callback.SPX_OBJVAL)\n",
    "        if model.cbGet(GRB.Callback.SPX_PRIMINF) == 0 and obj_best < -0.01: # and model.cbGet(GRB.Callback.SPX_DUALINF) == 0:\n",
    "            print(\"Used simplex terminate\")\n",
    "            model.terminate()\n",
    "    if where == GRB.Callback.BARRIER:\n",
    "        obj_best = model.cbGet(GRB.Callback.SPX_OBJVAL)\n",
    "        if model.cbGet(GRB.Callback.BARRIER_PRIMINF) == 0  and obj_best < -0.01: # and model.cbGet(GRB.Callback.BARRIER_DUALINF) == 0\n",
    "            model.terminate()\n",
    "            print(\"Used barrier terminate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_conv(model, var_list, start_counter, filters,biases,filter_size,input_shape, strides, out_shape, pad_top,\n",
    "                pad_left, pad_bottom, pad_right, lbi, ubi, use_milp, is_nchw=False):\n",
    "\n",
    "    num_out_neurons = np.prod(out_shape)\n",
    "    num_in_neurons = np.prod(input_shape)#input_shape[0]*input_shape[1]*input_shape[2]\n",
    "    #print(\"filters\", filters.shape, filter_size, input_shape, strides, out_shape, pad_top, pad_left)\n",
    "    start = len(var_list)\n",
    "    for j in range(num_out_neurons):\n",
    "        var_name = \"x\" + str(start+j)\n",
    "        var = model.addVar(vtype=GRB.CONTINUOUS, lb=lbi[j], ub =ubi[j], name=var_name)\n",
    "        var_list.append(var)\n",
    "\n",
    "    #print(\"OUT SHAPE \", out_shape, input_shape, filter_size, filters.shape, biases.shape)\n",
    "    if is_nchw:\n",
    "        for out_z in range(out_shape[1]):\n",
    "            for out_x in range(out_shape[2]):\n",
    "                for out_y in range(out_shape[3]):\n",
    "                \n",
    "                    dst_ind = out_z*out_shape[2]*out_shape[3] + out_x*out_shape[3] + out_y\n",
    "                    expr = LinExpr()\n",
    "                    #print(\"dst ind \", dst_ind)\n",
    "                    expr += -1*var_list[start+dst_ind]\n",
    "                    \n",
    "                    for inp_z in range(input_shape[0]):\n",
    "                        for x_shift in range(filter_size[0]):\n",
    "                            for y_shift in range(filter_size[1]):\n",
    "                                x_val = out_x*strides[0]+x_shift-pad_top\n",
    "                                y_val = out_y*strides[1]+y_shift-pad_left\n",
    "                                if(y_val<0 or y_val >= input_shape[2]):\n",
    "                                    continue\n",
    "                                if(x_val<0 or x_val >= input_shape[1]):\n",
    "                                    continue\n",
    "                                mat_offset = x_val*input_shape[2] + y_val + inp_z*input_shape[1]*input_shape[2]\n",
    "                                if(mat_offset>=num_in_neurons):\n",
    "                                    continue \n",
    "                                src_ind = start_counter + mat_offset\n",
    "                                #print(\"src ind \", mat_offset)\n",
    "                                #filter_index = x_shift*filter_size[1]*input_shape[0]*out_shape[1] + y_shift*input_shape[0]*out_shape[1] + inp_z*out_shape[1] + out_z\n",
    "                                expr.addTerms(filters[out_z][inp_z][x_shift][y_shift],var_list[src_ind])\n",
    "                                                           \n",
    "                    expr.addConstant(biases[out_z])\n",
    "                    \n",
    "                    model.addConstr(expr, GRB.EQUAL, 0)  \n",
    "                      \n",
    "    else:\n",
    "        for out_x in range(out_shape[1]):\n",
    "            for out_y in range(out_shape[2]):\n",
    "                for out_z in range(out_shape[3]):\n",
    "                    dst_ind = out_x*out_shape[2]*out_shape[3] + out_y*out_shape[3] + out_z\n",
    "                    expr = LinExpr()\n",
    "                    expr += -1*var_list[start+dst_ind]\n",
    "                    for inp_z in range(input_shape[2]):\n",
    "                        for x_shift in range(filter_size[0]):\n",
    "                            for y_shift in range(filter_size[1]):\n",
    "                                x_val = out_x*strides[0]+x_shift-pad_top\n",
    "                                y_val = out_y*strides[1]+y_shift-pad_left\n",
    "\n",
    "                                if(y_val<0 or y_val >= input_shape[1]):\n",
    "                                    continue\n",
    "\n",
    "                                if(x_val<0 or x_val >= input_shape[0]):\n",
    "                                    continue\n",
    "\n",
    "                                mat_offset = x_val*input_shape[1]*input_shape[2] + y_val*input_shape[2] + inp_z\n",
    "                                if(mat_offset>=num_in_neurons):\n",
    "                                    continue\n",
    "                                src_ind = start_counter + mat_offset\n",
    "                                #filter_index = x_shift*filter_size[1]*input_shape[2]*out_shape[3] + y_shift*input_shape[2]*out_shape[3] + inp_z*out_shape[3] + out_z\n",
    "                             #expr.addTerms(filters[filter_index],var_list[src_ind])\n",
    "                                expr.addTerms(filters[x_shift][y_shift][inp_z][out_z],var_list[src_ind])\n",
    "\n",
    "                    expr.addConstant(biases[out_z])\n",
    "                    model.addConstr(expr, GRB.EQUAL, 0)\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff210e0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def handle_padding(model, var_list, start_counter, input_shape, out_shape, pad_top, pad_left, pad_bottom, pad_right, lbi, ubi, is_nchw=False):\n",
    "    num_out_neurons = np.prod(out_shape)\n",
    "    num_in_neurons = np.prod(input_shape)  # input_shape[0]*input_shape[1]*input_shape[2]\n",
    "    # print(\"filters\", filters.shape, filter_size, input_shape, strides, out_shape, pad_top, pad_left)\n",
    "    start = len(var_list)\n",
    "    for j in range(num_out_neurons):\n",
    "        var_name = \"x\" + str(start + j)\n",
    "        var = model.addVar(vtype=GRB.CONTINUOUS, lb=lbi[j], ub=ubi[j], name=var_name)\n",
    "        var_list.append(var)\n",
    "\n",
    "    # print(\"OUT SHAPE \", out_shape, input_shape, filter_size, filters.shape, biases.shape)\n",
    "    if is_nchw:\n",
    "        for out_z in range(out_shape[1]):\n",
    "            for out_x in range(out_shape[2]):\n",
    "                for out_y in range(out_shape[3]):\n",
    "\n",
    "                    dst_ind = out_z * out_shape[2] * out_shape[3] + out_x * out_shape[3] + out_y\n",
    "                    expr = LinExpr()\n",
    "                    expr += -1 * var_list[start + dst_ind]\n",
    "\n",
    "                    x_val = out_x  - pad_top\n",
    "                    y_val = out_y  - pad_left\n",
    "                    mat_offset = out_z * input_shape[1] * input_shape[2] + x_val * input_shape[2] + y_val\n",
    "\n",
    "                    if (y_val < 0 or y_val >= input_shape[2]):\n",
    "                        pass\n",
    "                    elif (x_val < 0 or x_val >= input_shape[1]):\n",
    "                        pass\n",
    "                    elif (mat_offset >= num_in_neurons):\n",
    "                        pass\n",
    "                    else:\n",
    "                        expr += 1 * var_list[start_counter + mat_offset]\n",
    "                    model.addConstr(expr, GRB.EQUAL, 0)\n",
    "\n",
    "    else:\n",
    "        for out_x in range(out_shape[1]):\n",
    "            for out_y in range(out_shape[2]):\n",
    "                for out_z in range(out_shape[3]):\n",
    "                    dst_ind = out_x * out_shape[2] * out_shape[3] + out_y * out_shape[3] + out_z\n",
    "                    expr = LinExpr()\n",
    "                    expr += -1 * var_list[start + dst_ind]\n",
    "                    x_val = out_x - pad_top\n",
    "                    y_val = out_y - pad_left\n",
    "                    mat_offset = x_val * input_shape[1] * input_shape[2] + y_val * input_shape[2] + out_z\n",
    "\n",
    "                    if (y_val < 0 or y_val >= input_shape[1]):\n",
    "                        pass\n",
    "                    elif (x_val < 0 or x_val >= input_shape[0]):\n",
    "                        pass\n",
    "                    elif (mat_offset >= num_in_neurons):\n",
    "                        pass\n",
    "                    else:\n",
    "                        expr += 1 * var_list[start_counter + mat_offset]\n",
    "\n",
    "                    model.addConstr(expr, GRB.EQUAL, 0)\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc2fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_maxpool(model, var_list, layerno, src_counter, pool_size, input_shape, strides, output_shape, pad_top,\n",
    "                   pad_left, lbi, ubi, lbi_prev, ubi_prev, use_milp, is_nchw=False):\n",
    "    use_milp = use_milp and config.use_milp\n",
    "\n",
    "    start = len(var_list)\n",
    "    num_neurons = np.prod(input_shape)#input_shape[0]*input_shape[1]*input_shape[2]\n",
    "    num_neurons_out = np.prod(output_shape)\n",
    "    pool_count = np.prod(pool_size)\n",
    "    binary_counter = start\n",
    "    maxpool_counter = start\n",
    "\n",
    "    if(use_milp==1):\n",
    "        maxpool_counter = start + num_neurons_out * pool_count\n",
    "        for j in range(num_neurons_out):\n",
    "            for i in range(pool_count):\n",
    "                var_name = \"x\" + str(maxpool_counter+j) + \"_\" + str(i)\n",
    "                var = model.addVar(vtype=GRB.BINARY, name=var_name)\n",
    "                var_list.append(var)\n",
    "\n",
    "    o1 = output_shape[1]\n",
    "    o2 = output_shape[2]\n",
    "    o3 = output_shape[3]\n",
    "    output_size = o1*o2*o3\n",
    "    i12 = input_shape[1]*input_shape[2]\n",
    "    o12 = output_shape[2]*output_shape[3]\n",
    "\n",
    "    #print(\"strides \", strides, pad_top, pad_left)\n",
    "    for j in range(output_size):\n",
    "        var_name = \"x\" + str(maxpool_counter+j)\n",
    "        var = model.addVar(vtype=GRB.CONTINUOUS, lb=lbi[j], ub=ubi[j],  name=var_name)\n",
    "        var_list.append(var)\n",
    "\n",
    "    for out_pos in range(output_size):\n",
    "        if is_nchw:\n",
    "            out_z = int(out_pos / o12)\n",
    "            out_x = int((out_pos - out_z * o12) / output_shape[3])\n",
    "            out_y = int(out_pos - out_z * o12 - out_x * output_shape[3])\n",
    "        else:\n",
    "            out_x = int(out_pos / o12)\n",
    "            out_y = int((out_pos-out_x*o12) / output_shape[3])\n",
    "            out_z = int(out_pos-out_x*o12 - out_y*output_shape[3])\n",
    "        inp_z = out_z\n",
    "               \n",
    "        max_u = float(\"-inf\")\n",
    "        max_l = float(\"-inf\")\n",
    "        sum_l = 0.0\n",
    "        max_l_var = 0\n",
    "        max_u_var = 0\n",
    "        pool_map = []\n",
    "        l = 0\n",
    "        for x_shift in range(pool_size[0]):\n",
    "            for y_shift in range(pool_size[1]):\n",
    "                x_val = out_x*strides[0] + x_shift - pad_top\n",
    "                if(x_val<0 or (x_val>=input_shape[1] if is_nchw else x_val>=input_shape[0])):\n",
    "                    continue\n",
    "                y_val = out_y*strides[1] + y_shift - pad_left\n",
    "                if(y_val < 0 or (y_val>=input_shape[2] if is_nchw else y_val>=input_shape[1])):\n",
    "                    continue\n",
    "                if is_nchw:\n",
    "                    pool_cur_dim = inp_z * i12 + x_val * input_shape[2] + y_val\n",
    "                else:\n",
    "                    pool_cur_dim = x_val * i12 + y_val * input_shape[2] + inp_z\n",
    "                if pool_cur_dim >= num_neurons:\n",
    "                    continue    \n",
    "                pool_map.append(pool_cur_dim)\n",
    "                lb = lbi_prev[pool_cur_dim] \n",
    "                ub = ubi_prev[pool_cur_dim]\n",
    "                sum_l = sum_l + lb       \n",
    "                if lb > max_l:\n",
    "                    max_l = lb\n",
    "                    max_l_var = pool_cur_dim\n",
    "                if ub > max_u:\n",
    "                    max_u = ub\n",
    "                    max_u_var = pool_cur_dim\n",
    "\n",
    "                l = l + 1     \n",
    "        dst_index = maxpool_counter + out_pos\n",
    "\n",
    "        # if ubi[out_pos] < max(*(ubi_prev[i] for i in pool_map)):\n",
    "        #    print(\"tight bound found\")\n",
    "        # if lbi[out_pos] > max(*(lbi_prev[i] for i in pool_map)):\n",
    "        #    print(\"tight bound found\")\n",
    "\n",
    "        dominated = True\n",
    "        for l in pool_map:\n",
    "            if l == max_l_var:\n",
    "                continue\n",
    "            if ubi_prev[l] >= max_l:\n",
    "                dominated = False\n",
    "                break\n",
    "\n",
    "        if dominated:\n",
    "            # one variable dominates all others\n",
    "            src_var = max_l_var + src_counter\n",
    "            expr = var_list[dst_index] - var_list[src_var]\n",
    "            model.addConstr(expr, GRB.EQUAL, 0)\n",
    "        else:\n",
    "\n",
    "            if use_milp==1:\n",
    "                binary_expr = LinExpr()\n",
    "                for i, l in enumerate(range(len(pool_map))):\n",
    "                    src_index = pool_map[l]\n",
    "                    src_var = src_index + src_counter\n",
    "                    binary_var = out_pos * pool_count + i + binary_counter\n",
    "                    if(ubi_prev[src_index]<max_l):\n",
    "                        continue\n",
    "\n",
    "                    # y >= x\n",
    "                    expr = var_list[dst_index] - var_list[src_var]\n",
    "                    model.addConstr(expr, GRB.GREATER_EQUAL, 0)\n",
    "\n",
    "                    # y <= x + (1-a)*(u_{rest}-l)\n",
    "                    max_u_rest = float(\"-inf\")\n",
    "                    for j in pool_map:\n",
    "                        if j == src_index:\n",
    "                            continue\n",
    "                        if(ubi_prev[j]>max_u_rest):\n",
    "                            max_u_rest = ubi_prev[j]\n",
    "\n",
    "                    cst = max_u_rest-lbi_prev[src_index]\n",
    "                    expr = var_list[dst_index] - var_list[src_var] + cst * (var_list[binary_var] - 1)\n",
    "                    model.addConstr(expr, GRB.LESS_EQUAL, 0, name=f\"max_pool_{dst_index}_{i}\")\n",
    "\n",
    "                    # indicator constraints\n",
    "                    model.addGenConstrIndicator(var_list[binary_var], True, var_list[dst_index]-var_list[src_var], GRB.EQUAL, 0.0)\n",
    "                    binary_expr += var_list[binary_var]\n",
    "\n",
    "                # only one indicator can be true\n",
    "                model.addConstr(binary_expr, GRB.EQUAL, 1, name=f\"binary_max_pool_{dst_index}\")\n",
    "\n",
    "            else:\n",
    "                # No one variable dominates all other\n",
    "                add_expr = LinExpr()\n",
    "                add_expr += -var_list[dst_index]\n",
    "                for l in range(len(pool_map)):\n",
    "                    src_index = pool_map[l]\n",
    "                    src_var = src_index + src_counter\n",
    "                    # y >= x\n",
    "                    expr = var_list[dst_index] - var_list[src_var]\n",
    "                    model.addConstr(expr, GRB.GREATER_EQUAL, 0)\n",
    "\n",
    "                    add_expr += var_list[src_var]\n",
    "                model.addConstr(add_expr, GRB.GREATER_EQUAL, sum_l - max_l)\n",
    "\n",
    "    return maxpool_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c779087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_affine(model,var_list,counter,weights,biases, lbi, ubi):\n",
    "    num_neurons_affine = len(weights)\n",
    "    start = len(var_list)\n",
    "\n",
    "    # output of matmult\n",
    "    for j in range(num_neurons_affine):\n",
    "        var_name = \"x\" + str(start+j)\n",
    "        var = model.addVar(vtype=GRB.CONTINUOUS, lb=lbi[j], ub=ubi[j], name=var_name)\n",
    "        var_list.append(var)\n",
    "\n",
    "    for j in range(num_neurons_affine):\n",
    "        num_in_neurons = len(weights[j])\n",
    "\n",
    "        expr = LinExpr()\n",
    "        expr += -1*var_list[start+j]\n",
    "        # matmult constraints\n",
    "        for k in range(num_in_neurons):\n",
    "            expr.addTerms(weights[j][k], var_list[counter+k])\n",
    "        expr.addConstant(biases[j])\n",
    "        model.addConstr(expr, GRB.EQUAL, 0)\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3869bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_residual(model, var_list, branch1_counter, branch2_counter, lbi, ubi):\n",
    "    num_neurons_affine = len(lbi)\n",
    "    start = len(var_list)\n",
    "\n",
    "    # output of matmult\n",
    "    for j in range(num_neurons_affine):\n",
    "        var_name = \"x\" + str(start + j)\n",
    "        var = model.addVar(vtype=GRB.CONTINUOUS, lb=lbi[j], ub=ubi[j], name=var_name)\n",
    "        var_list.append(var)\n",
    "\n",
    "    for j in range(num_neurons_affine):\n",
    "        # num_in_neurons = len(weights[j])\n",
    "\n",
    "        expr = LinExpr()\n",
    "        expr += -1 * var_list[start + j]\n",
    "        # matmult constraints\n",
    "        # for k in range(num_in_neurons):\n",
    "        expr += var_list[branch1_counter + j]\n",
    "        expr += var_list[branch2_counter + j]\n",
    "        expr.addConstant(0)\n",
    "        model.addConstr(expr, GRB.EQUAL, 0)\n",
    "    return start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_kactivation_constraints(model, var_list, constraint_groups, x_counter, y_counter):\n",
    "    #print(\"start here \")\n",
    "    for inst in constraint_groups:\n",
    "        for row in inst.cons:\n",
    "            k = len(inst.varsid)\n",
    "            expr = LinExpr()\n",
    "            expr.addConstant(row[0])\n",
    "            for i, x in enumerate(inst.varsid):\n",
    "                expr.addTerms(row[1 + i], var_list[x_counter + x])\n",
    "                expr.addTerms(row[1 + k + i], var_list[y_counter + x])\n",
    "            #print(\"row \", row)\n",
    "            model.addConstr(expr >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff51c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_relu(model,var_list, affine_counter, num_neurons, lbi, ubi, relu_groupsi, use_milp, partial_milp_neurons):\n",
    "    use_milp = use_milp and config.use_milp\n",
    "    print(\"handle_relu -\")\n",
    "\n",
    "    start = len(var_list)\n",
    "    relu_counter = start\n",
    "\n",
    "    cross_over_idx = list(np.nonzero(np.array(lbi)*np.array(ubi)<0)[0])\n",
    "    width = np.array(ubi) - np.array(lbi)\n",
    "    cross_over_idx = sorted(cross_over_idx, key= lambda x: -width[x])\n",
    "    \n",
    "    print(\"cross_over_idx\",cross_over_idx)\n",
    "\n",
    "    milp_encode_idx = cross_over_idx[:partial_milp_neurons] if partial_milp_neurons>=0 else cross_over_idx #cross_over_idx if use_milp else cross_over_idx[:partial_milp_neurons]\n",
    "    temp_idx = np.ones(num_neurons, dtype=bool)\n",
    "    temp_idx[milp_encode_idx] = False\n",
    "    relax_encode_idx = np.arange(num_neurons)[temp_idx]\n",
    "\n",
    "    assert len(relax_encode_idx) + len(milp_encode_idx) == num_neurons\n",
    "\n",
    "    print(\"neurons \", num_neurons)\n",
    "    \n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    \n",
    "    if len(milp_encode_idx)>0:\n",
    "        for i, j in enumerate(milp_encode_idx):\n",
    "            var_name = \"b_bin_\" + str(start + i)\n",
    "            var_bin = model.addVar(vtype=GRB.BINARY, name=var_name)\n",
    "            var_list.append(var_bin)\n",
    "            relu_counter += 1\n",
    "\n",
    "    # relu output variables\n",
    "    for j in range(num_neurons):\n",
    "        var_name = \"b\" + str(relu_counter+j)\n",
    "        upper_bound = max(0.0, ubi[j])\n",
    "        var = model.addVar(vtype=GRB.CONTINUOUS, lb=0.0, ub=upper_bound,  name=var_name)\n",
    "        var_list.append(var)\n",
    "\n",
    "\n",
    "    if len(milp_encode_idx)>0:\n",
    "        print(\"milp_encode_idx neurons \", num_neurons)\n",
    "        for i, j in enumerate(milp_encode_idx):\n",
    "            var_bin = var_list[start+i]\n",
    "\n",
    "            if(ubi[j]<=0):\n",
    "               expr = var_list[relu_counter+j]\n",
    "               model.addConstr(expr, GRB.EQUAL, 0)\n",
    "            elif(lbi[j]>=0):\n",
    "               expr = var_list[relu_counter+j] - var_list[affine_counter+j]\n",
    "               model.addConstr(expr, GRB.EQUAL, 0)\n",
    "            else:\n",
    "               # y <= x - l(1-a)\n",
    "               expr = var_list[relu_counter+j] - var_list[affine_counter+j] - lbi[j] * var_bin\n",
    "               model.addConstr(expr, GRB.LESS_EQUAL, -lbi[j])\n",
    "\n",
    "               # y >= x\n",
    "               expr = var_list[relu_counter+j] - var_list[affine_counter+j]\n",
    "               model.addConstr(expr, GRB.GREATER_EQUAL, 0)\n",
    "\n",
    "               # y <= u . a\n",
    "               expr = var_list[relu_counter+j] - ubi[j] * var_bin\n",
    "               model.addConstr(expr, GRB.LESS_EQUAL, 0)\n",
    "\n",
    "               # y >= 0\n",
    "               expr = var_list[relu_counter+j]\n",
    "               model.addConstr(expr, GRB.GREATER_EQUAL, 0)\n",
    "\n",
    "               # indicator constraint\n",
    "               model.addGenConstrIndicator(var_bin, True, var_list[affine_counter+j], GRB.GREATER_EQUAL, 0.0)\n",
    "\n",
    "    if len(relax_encode_idx) > 0:\n",
    "        for j in relax_encode_idx:\n",
    "            if ubi[j] <= 0:\n",
    "                expr = var_list[relu_counter+j]\n",
    "                model.addConstr(expr, GRB.EQUAL, 0)\n",
    "            elif lbi[j] >= 0:\n",
    "                expr = var_list[relu_counter+j] - var_list[affine_counter+j]\n",
    "                model.addConstr(expr, GRB.EQUAL, 0)\n",
    "\n",
    "    if len(relu_groupsi) > 0:\n",
    "        _add_kactivation_constraints(model, var_list, relu_groupsi, affine_counter, relu_counter)\n",
    "    else:\n",
    "        for j in relax_encode_idx:\n",
    "            if (lbi[j] < 0) and (ubi[j] > 0):\n",
    "                expr = -ubi[j] * var_list[affine_counter+j]\n",
    "                expr += (ubi[j] - lbi[j]) * var_list[relu_counter+j]\n",
    "                expr += lbi[j] * ubi[j]\n",
    "                model.addConstr(expr, GRB.LESS_EQUAL, 0)\n",
    "\n",
    "    return relu_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97d5fb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def handle_sign(model,var_list, affine_counter, num_neurons, lbi, ubi):\n",
    "    start= len(var_list)\n",
    "    binary_counter = start\n",
    "    sign_counter = start + num_neurons\n",
    "    for j in range(num_neurons):\n",
    "        var_name = \"x\" + str(start+j)\n",
    "        var = model.addVar(vtype=GRB.BINARY, name=var_name)\n",
    "        var_list.append(var)\n",
    "\n",
    "    # sign variables\n",
    "    for j in range(num_neurons):\n",
    "        var_name = \"x\" + str(sign_counter+j)\n",
    "        var = model.addVar(vtype=GRB.CONTINUOUS, lb = 0.0, ub=1.0,  name=var_name)\n",
    "        var_list.append(var)\n",
    "\n",
    "\n",
    "    for j in range(num_neurons):\n",
    "        if(ubi[j]<=0):\n",
    "            expr = var_list[sign_counter+j]\n",
    "            model.addConstr(expr, GRB.EQUAL, 0)\n",
    "        elif(lbi[j]>=0):\n",
    "            expr = var_list[sign_counter+j] - var_list[affine_counter+j]\n",
    "            model.addConstr(expr, GRB.EQUAL, 1)\n",
    "        else:\n",
    "            # x >= l(1-a)\n",
    "            expr = - var_list[affine_counter+j] - lbi[j]*var_list[binary_counter+j]\n",
    "            model.addConstr(expr, GRB.LESS_EQUAL, -lbi[j])\n",
    "\n",
    "\n",
    "            # x <= u.a\n",
    "            expr = var_list[affine_counter+j] - ubi[j]*var_list[binary_counter+j]\n",
    "            model.addConstr(expr, GRB.LESS_EQUAL, 0)\n",
    "\n",
    "            # y = a\n",
    "            expr = var_list[sign_counter+j]\n",
    "            model.addConstr(expr, GRB.GREATER_EQUAL, var_list[binary_counter+j])\n",
    "\n",
    "            # indicator constraint\n",
    "            model.addGenConstrIndicator(var_list[binary_counter+j], True, var_list[affine_counter+j], GRB.GREATER_EQUAL, 0.0)\n",
    "\n",
    "    return sign_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed847f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84716962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tanh_sigmoid(model, var_list, affine_counter, num_neurons, lbi, ubi,\n",
    "                        constraint_groups, activation_type):\n",
    "    assert activation_type in [\"Tanh\", \"Sigmoid\"]\n",
    "    y_counter = len(var_list)\n",
    "\n",
    "    for j in range(num_neurons):\n",
    "        var_name = \"x\" + str(y_counter + j)\n",
    "        x_lb = lbi[j]\n",
    "        x_ub = ubi[j]\n",
    "        if activation_type == \"Tanh\":\n",
    "            var = model.addVar(vtype=GRB.CONTINUOUS, lb=math.tanh(x_lb), ub=math.tanh(x_ub), name=var_name)\n",
    "        else:\n",
    "            var = model.addVar(vtype=GRB.CONTINUOUS, lb=sigmoid(x_lb), ub=sigmoid(x_ub), name=var_name)\n",
    "        var_list.append(var)\n",
    "\n",
    "    _add_kactivation_constraints(model, var_list, constraint_groups, affine_counter, y_counter)\n",
    "\n",
    "    return y_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070bf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nn, LB_N0, UB_N0, nlb, nub, relu_groups, numlayer, use_milp, is_nchw=False, partial_milp=0, max_milp_neurons=-1):\n",
    "    print(\"create_model -\")\n",
    "    model = Model(\"milp\")\n",
    "\n",
    "    model.setParam(\"OutputFlag\",1)\n",
    "    model.setParam(GRB.Param.FeasibilityTol, 2e-5)\n",
    "\n",
    "    milp_activation_layers = np.nonzero([l in [\"ReLU\", \"Maxpool\"] for l in nn.layertypes])[0]\n",
    "\n",
    "    ### Determine whcich layers, if any to encode with MILP\n",
    "    if partial_milp < 0:\n",
    "        partial_milp = len(milp_activation_layers)\n",
    "    first_milp_layer = len(nn.layertypes) if partial_milp == 0 else milp_activation_layers[-min(partial_milp, len(milp_activation_layers))]\n",
    "\n",
    "    num_pixels = len(LB_N0)\n",
    "\n",
    "    ### Set layer counters to 0, later used to access layer resources\n",
    "    ffn_counter = 0\n",
    "    conv_counter = 0\n",
    "    residual_counter = 0\n",
    "    pool_counter = 0\n",
    "    pad_counter = 0\n",
    "    activation_counter = 0\n",
    "\n",
    "    var_list = []\n",
    "    counter = 0\n",
    "\n",
    "    ### Encode inputs, either from box or zonotope\n",
    "    if len(UB_N0)==0:\n",
    "        ### Zonotope\n",
    "        num_pixels = nn.zonotope.shape[0]\n",
    "        num_error_terms = nn.zonotope.shape[1]\n",
    "        for j in range(num_error_terms-1):\n",
    "            var_name = \"e\" + str(j)\n",
    "            var = model.addVar(vtype=GRB.CONTINUOUS, lb=-1, ub=1, name=var_name)\n",
    "            var_list.append(var)\n",
    "        counter = num_error_terms-1\n",
    "        for i in range(num_pixels):\n",
    "            lower_bound = nn.zonotope[i][0]\n",
    "            upper_bound = lower_bound\n",
    "            for j in range(1,num_error_terms):\n",
    "                lower_bound = lower_bound - abs(nn.zonotope[i][j])\n",
    "                upper_bound = upper_bound + abs(nn.zonotope[i][j])\n",
    "            var_name = \"x\" + str(i)\n",
    "            var = model.addVar(vtype=GRB.CONTINUOUS, lb=lower_bound, ub=upper_bound, name=var_name)\n",
    "            var_list.append(var)\n",
    "            expr = LinExpr()\n",
    "            expr += -1 * var_list[counter + i]\n",
    "            for j in range(num_error_terms-1):\n",
    "                expr.addTerms(nn.zonotope[i][j+1], var_list[j])\n",
    "\n",
    "            expr.addConstant(nn.zonotope[i][0])\n",
    "            model.addConstr(expr, GRB.EQUAL, 0)\n",
    "    else:\n",
    "        for i in range(num_pixels):\n",
    "            var_name = \"a\" + str(i)\n",
    "            var = model.addVar(vtype=GRB.CONTINUOUS, lb=LB_N0[i], ub=UB_N0[i], name=var_name)\n",
    "            var_list.append(var)\n",
    "\n",
    "    start_counter = []\n",
    "    start_counter.append(counter)\n",
    "    ### Add layers to model one by one\n",
    "    for i in range(numlayer):\n",
    "        if nn.layertypes[i] in ['SkipCat']:\n",
    "            continue\n",
    "        elif nn.layertypes[i] in ['FC']:\n",
    "            weights = nn.weights[ffn_counter]\n",
    "            biases = nn.biases[ffn_counter+conv_counter]\n",
    "            index = nn.predecessors[i+1][0]\n",
    "            #print(\"index \", index, start_counter,i, len(relu_groups))\n",
    "            counter = start_counter[index]\n",
    "            counter = handle_affine(model, var_list, counter, weights, biases, nlb[i], nub[i])\n",
    "            ffn_counter += 1\n",
    "            start_counter.append(counter)\n",
    "\n",
    "        elif(nn.layertypes[i]=='ReLU'):\n",
    "            index = nn.predecessors[i+1][0]\n",
    "            partial_milp_neurons = (first_milp_layer <= i) * (max_milp_neurons if max_milp_neurons >= 0 else len(nlb[i]))\n",
    "            if relu_groups is None:\n",
    "                counter = handle_relu(model, var_list, counter, len(nlb[i]), nlb[index-1], nub[index-1], [], use_milp, partial_milp_neurons)\n",
    "            else:\n",
    "                counter = handle_relu(model, var_list, counter, len(nlb[i]), nlb[index-1], nub[index-1], relu_groups[activation_counter], use_milp, partial_milp_neurons)\n",
    "            activation_counter += 1\n",
    "            start_counter.append(counter)\n",
    "\n",
    "        elif nn.layertypes[i] == 'Sigmoid' or nn.layertypes[i] == 'Tanh':\n",
    "            index = nn.predecessors[i+1][0]\n",
    "            if relu_groups is None:\n",
    "                counter = handle_tanh_sigmoid(model, var_list, counter, len(nlb[i]), nlb[index-1], nub[index-1],\n",
    "                                          [], nn.layertypes[i])\n",
    "            else:\n",
    "                counter = handle_tanh_sigmoid(model, var_list, counter, len(nlb[i]), nlb[index-1], nub[index-1],\n",
    "                                          relu_groups[activation_counter], nn.layertypes[i])\n",
    "            activation_counter += 1\n",
    "            start_counter.append(counter)\n",
    "            \n",
    "        elif nn.layertypes[i] == 'Sign':\n",
    "            index = nn.predecessors[i+1][0]\n",
    "            counter = handle_sign(model, var_list, counter, len(nlb[i]), nlb[index-1], nub[index-1])\n",
    "            activation_counter += 1\n",
    "            start_counter.append(counter)\n",
    "\n",
    "        elif nn.layertypes[i] in ['Conv']:\n",
    "            filters = nn.filters[conv_counter]\n",
    "            biases = nn.biases[ffn_counter + conv_counter]\n",
    "            filter_size = nn.filter_size[conv_counter]\n",
    "            out_shape = nn.out_shapes[conv_counter + pool_counter + pad_counter]\n",
    "            padding = nn.padding[conv_counter + pool_counter + pad_counter]\n",
    "            strides = nn.strides[conv_counter + pool_counter]\n",
    "            input_shape = nn.input_shape[conv_counter + pool_counter + pad_counter]\n",
    "            index = nn.predecessors[i+1][0]\n",
    "            counter = start_counter[index]\n",
    "            counter = handle_conv(model, var_list, counter, filters, biases, filter_size, input_shape, strides,\n",
    "                                  out_shape, padding[0], padding[1], padding[2], padding[3], nlb[i], nub[i], use_milp, is_nchw=is_nchw)\n",
    "            start_counter.append(counter)\n",
    "            conv_counter += 1\n",
    "\n",
    "        elif(nn.layertypes[i] in ['Maxpool',\"MaxPool\"]):\n",
    "            partial_milp_neurons = (first_milp_layer <= i) * (max_milp_neurons if max_milp_neurons >= 0 else len(nlb[i]))\n",
    "            pool_size = nn.pool_size[pool_counter]\n",
    "            input_shape = nn.input_shape[conv_counter + pool_counter + pad_counter]\n",
    "            out_shape = nn.out_shapes[conv_counter + pool_counter + pad_counter]\n",
    "            padding = nn.padding[conv_counter + pool_counter + pad_counter]\n",
    "            strides = nn.strides[conv_counter + pool_counter]\n",
    "            index = nn.predecessors[i+1][0]\n",
    "            counter = start_counter[index]\n",
    "            counter = handle_maxpool(model, var_list, i, counter, pool_size, input_shape, strides, out_shape, padding[0],\n",
    "                                     padding[1], nlb[i], nub[i], nlb[i-1], nub[i-1], use_milp, is_nchw=is_nchw)\n",
    "            start_counter.append(counter)\n",
    "            pool_counter += 1\n",
    "\n",
    "        elif(nn.layertypes[i]=='Pad'):\n",
    "            input_shape = nn.input_shape[conv_counter + pool_counter + pad_counter]\n",
    "            out_shape = nn.out_shapes[conv_counter + pool_counter + pad_counter]\n",
    "            padding = nn.padding[conv_counter + pool_counter + pad_counter]\n",
    "            index = nn.predecessors[i+1][0]\n",
    "            counter = start_counter[index]\n",
    "            counter = handle_padding(model, var_list, counter, input_shape, out_shape, padding[0], padding[1], padding[2], padding[3], nlb[i], nub[i], is_nchw=is_nchw)\n",
    "            start_counter.append(counter)\n",
    "            pad_counter += 1\n",
    "\n",
    "        elif nn.layertypes[i] in ['Resadd']:\n",
    "            index1 = nn.predecessors[i+1][0]\n",
    "            index2 = nn.predecessors[i+1][1]\n",
    "            counter1 = start_counter[index1]\n",
    "            counter2 = start_counter[index2]\n",
    "            counter = handle_residual(model, var_list, counter1, counter2, nlb[i], nub[i])\n",
    "            start_counter.append(counter)\n",
    "            residual_counter += 1\n",
    "\n",
    "        elif nn.layertypes[i] in ['Pad']:\n",
    "            raise NotImplementedError\n",
    "        else:\n",
    "            assert 0, 'layertype:' + nn.layertypes[i] + 'not supported for refine'\n",
    "\n",
    "    #model.write(\"model_refinepoly.lp\")\n",
    "    #np.set_printoptions(threshold=sys.maxsize)\n",
    "    #print(\"NLB \", nlb[-4], len(nlb[-4]))\n",
    "    return counter, var_list, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    model = None\n",
    "    output_counter = None\n",
    "    lbi = None\n",
    "    ubi = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436281bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver_call(ind):\n",
    "    ### Call solver to compute neuronwise bounds in parallel\n",
    "    model = Cache.model.copy()\n",
    "    runtime = 0\n",
    "\n",
    "    obj = LinExpr()\n",
    "    obj += model.getVars()[Cache.output_counter+ind]\n",
    "    #print (f\"{ind} {model.getVars()[Cache.output_counter+ind].VarName}\")\n",
    "\n",
    "    model.setObjective(obj, GRB.MINIMIZE)\n",
    "    model.reset()\n",
    "    model.optimize()\n",
    "    runtime += model.RunTime\n",
    "    soll = Cache.lbi[ind] if model.SolCount==0 else model.objbound\n",
    "    # print (f\"{ind} {model.status} lb ({Cache.lbi[ind]}, {soll}) {model.RunTime}s\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    model.setObjective(obj, GRB.MAXIMIZE)\n",
    "    model.reset()\n",
    "    model.optimize()\n",
    "    runtime += model.RunTime\n",
    "    solu = Cache.ubi[ind] if model.SolCount==0 else model.objbound\n",
    "    # print (f\"{ind} {model.status} ub ({Cache.ubi[ind]}, {solu}) {model.RunTime}s\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    soll = max(soll, Cache.lbi[ind])\n",
    "    solu = min(solu, Cache.ubi[ind])\n",
    "\n",
    "    addtoindices = (soll > Cache.lbi[ind]) or (solu < Cache.ubi[ind])\n",
    "\n",
    "    return soll, solu, addtoindices, runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounds_for_layer_with_milp(nn, LB_N0, UB_N0, layerno, abs_layer_count, output_size, nlb, nub, relu_groups, use_milp, candidate_vars, timeout):\n",
    "    lbi = nlb[abs_layer_count]\n",
    "    ubi = nub[abs_layer_count]\n",
    "\n",
    "    widths = [u-l for u, l in zip(ubi,lbi)]\n",
    "\n",
    "    candidate_vars = sorted(candidate_vars, key=lambda k: widths[k])\n",
    "    counter, var_list, model = create_model(nn, LB_N0, UB_N0, nlb, nub, relu_groups, layerno+1, use_milp, partial_milp=-1, max_milp_neurons=-1)\n",
    "    resl = [0]*len(lbi)\n",
    "    resu = [0]*len(ubi)\n",
    "    indices = []\n",
    "\n",
    "    model.setParam(GRB.Param.TimeLimit, timeout)\n",
    "    model.setParam(GRB.Param.Threads, 2)\n",
    "    output_counter = counter\n",
    "\n",
    "    model.update()\n",
    "    model.reset()\n",
    "\n",
    "    NUMPROCESSES = config.numproc\n",
    "    Cache.model = model\n",
    "    Cache.output_counter = output_counter\n",
    "    Cache.lbi = lbi\n",
    "    Cache.ubi = ubi\n",
    "\n",
    "    refined = [False]*len(lbi)\n",
    "\n",
    "    for v in candidate_vars:\n",
    "        refined[v] = True\n",
    "        #print (f\"{v} {deltas[v]} {widths[v]} {deltas[v]/widths[v]}\")\n",
    "    with multiprocessing.Pool(NUMPROCESSES) as pool:\n",
    "        solver_result = pool.map(solver_call, candidate_vars)\n",
    "\n",
    "    for (l, u, addtoindices, runtime), ind in zip(solver_result, candidate_vars):\n",
    "        resl[ind] = l\n",
    "        resu[ind] = u\n",
    "\n",
    "        if (l > u):\n",
    "            print(f\"unsound {ind}\")\n",
    "\n",
    "        if addtoindices:\n",
    "            indices.append(ind)\n",
    "\n",
    "    for i, flag in enumerate(refined):\n",
    "        if not flag:\n",
    "            resl[i] = lbi[i]\n",
    "            resu[i] = ubi[i]\n",
    "\n",
    "    for i in range(abs_layer_count):\n",
    "        for j in range(len(nlb[i])):\n",
    "            if(nlb[i][j]>nub[i][j]):\n",
    "                print(\"fp unsoundness detected \", nlb[i][j],nub[i][j],i,j)\n",
    "\n",
    "    return resl, resu, sorted(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092d815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spatial_constraints(model, spatial_constraints, var_list, input_size):\n",
    "\n",
    "    delta = spatial_constraints.get('delta')\n",
    "    gamma = spatial_constraints.get('gamma')\n",
    "    channels = spatial_constraints.get('channels')\n",
    "\n",
    "    lower_planes = spatial_constraints.get('lower_planes')\n",
    "    upper_planes = spatial_constraints.get('upper_planes')\n",
    "\n",
    "    add_norm_constraints = spatial_constraints.get('add_norm_constraints')\n",
    "    neighboring_indices = spatial_constraints.get('neighboring_indices')\n",
    "\n",
    "    vector_field = list()\n",
    "\n",
    "    for idx in range(input_size // channels):\n",
    "        vx = model.addVar(lb=-delta, ub=delta)\n",
    "        vy = model.addVar(lb=-delta, ub=delta)\n",
    "        add_norm_constraints(model, vx, vy)\n",
    "        vector_field.append({'vx': vx, 'vy': vy})\n",
    "\n",
    "    if (lower_planes is not None) and (upper_planes is not None):\n",
    "\n",
    "        for idx, vector in enumerate(vector_field):\n",
    "            for channel in range(channels):\n",
    "                index = channels * idx + channel\n",
    "                var = var_list[index]\n",
    "                lb_a, ub_a = lower_planes[0][index], upper_planes[0][index]\n",
    "                lb_b, ub_b = lower_planes[1][index], upper_planes[1][index]\n",
    "                lb_c, ub_c = lower_planes[2][index], upper_planes[2][index]\n",
    "\n",
    "                model.addConstr(\n",
    "                    var >= lb_a + lb_b * vector['vx'] + lb_c * vector['vy']\n",
    "                )\n",
    "                model.addConstr(\n",
    "                    var <= ub_a + ub_b * vector['vx'] + ub_c * vector['vy']\n",
    "                )\n",
    "\n",
    "    if (gamma is not None) and (gamma < float('inf')):\n",
    "\n",
    "        indices = neighboring_indices['indices'][::channels] // channels\n",
    "        neighbors = neighboring_indices['neighbors'][::channels] // channels\n",
    "\n",
    "        for idx, nbr in zip(indices.tolist(), neighbors.tolist()):\n",
    "            model.addConstr(\n",
    "                vector_field[idx]['vx'] - vector_field[nbr]['vx'] <= gamma\n",
    "            )\n",
    "            model.addConstr(\n",
    "                vector_field[nbr]['vx'] - vector_field[idx]['vx'] <= gamma\n",
    "            )\n",
    "            model.addConstr(\n",
    "                vector_field[idx]['vy'] - vector_field[nbr]['vy'] <= gamma\n",
    "            )\n",
    "            model.addConstr(\n",
    "                vector_field[nbr]['vy'] - vector_field[idx]['vy'] <= gamma\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_network_with_milp(nn, LB_N0, UB_N0, nlb, nub, constraints, spatial_constraints=None, is_nchw=False):\n",
    "    numlayer = nn.numlayer\n",
    "    input_size = len(LB_N0)\n",
    "    start_milp = time.time()\n",
    "    counter, var_list, model = create_model(nn, LB_N0, UB_N0, nlb, nub, None, numlayer, use_milp=True, is_nchw=is_nchw,\n",
    "                                            partial_milp=-1, max_milp_neurons=-1)\n",
    "    #print(\"timeout \", config.timeout_milp)\n",
    "\n",
    "    if spatial_constraints is not None:\n",
    "        add_spatial_constraints(model, spatial_constraints, var_list, input_size)\n",
    "                \n",
    "    adv_examples = []\n",
    "    non_adv_examples = []\n",
    "    adv_val = []\n",
    "    non_adv_val = []\n",
    "    for or_list in constraints:\n",
    "        or_result = False\n",
    "        for is_greater_tuple in or_list:\n",
    "            obj = obj_from_is_greater_tuple_old(is_greater_tuple, var_list, counter)\n",
    "            model.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "            # In some cases it occurs that Gurobi reports an infeasible model\n",
    "            # probably due to numerical difficulties (c.f. https://github.com/eth-sri/eran/issues/74).\n",
    "            # These can be resolved (in the cases considered) by increasing the Cutoff parameter.\n",
    "            # The code below tries to recover from an infeasible model by increasing the default cutoff\n",
    "            # a few times.\n",
    "            # 0.01 is the default cutoff value\n",
    "            for cutoff in [0.01, 0.1, GRB.INFINITY]:\n",
    "                model.reset()\n",
    "                milp_timeout = config.timeout_final_milp if config.timeout_complete is None else (config.timeout_complete + start_milp - time.time())\n",
    "                model.setParam(GRB.Param.TimeLimit, milp_timeout)\n",
    "                model.setParam(GRB.Param.Cutoff, cutoff)\n",
    "                model.optimize(milp_callback)\n",
    "                if model.status not in [3, 4]:  # status 3 and 4 indicate an infeasible model\n",
    "                    # no infeasibility reported.\n",
    "                    break\n",
    "                else:\n",
    "                    warnings.warn(\"Infeasible model encountered. Trying to increase the Cutoff parameter to recover.\")\n",
    "            else:\n",
    "                # all values led to an infeasible model\n",
    "                assert model.status not in [3, 4], f\"Infeasible model encountered. Model status {model.status}\"\n",
    "\n",
    "            obj_bound = f\"{model.objbound:.4f}\" if hasattr(model, \"objbound\") else \"failed\"\n",
    "            obj_val = f\"{model.objval:.4f}\" if hasattr(model, \"objval\") else \"failed\"\n",
    "            print(f\"MILP model status: {model.Status}, Obj val/bound for constraint {is_greater_tuple}: {obj_val}/{obj_bound}, Final solve time: {model.Runtime:.3f}\")\n",
    "\n",
    "            if model.Status == 6 or model.objbound > 0:\n",
    "                or_result = True\n",
    "                if model.solcount > 0:\n",
    "                    non_adv_examples.append(model.x[0:input_size])\n",
    "                    non_adv_val.append(model.objval)\n",
    "                break\n",
    "            elif model.solcount > 0:\n",
    "                adv_examples.append(model.x[0:input_size])\n",
    "                adv_val.append(model.objval)\n",
    "\n",
    "        if not or_result:\n",
    "            # Per default, we try to show that one of the elements of the or_list holds for the whole domain this might\n",
    "            # not be the case, even if the property holds. To find potential counterexamples, we add the negation of\n",
    "            # all or-clauses to the model and solve the corresponding feasibility problem.\n",
    "            # If this returns an infeasible model we allow this to be used for certification by setting\n",
    "            # certify_with_feasibility to True.\n",
    "            if len(or_list) > 1:\n",
    "                model.NumObj = 0\n",
    "                for i, is_greater_tuple in enumerate(or_list):\n",
    "                    obj_constr = obj_from_is_greater_tuple_old(is_greater_tuple, var_list, counter)\n",
    "                    model.addConstr(obj_constr, GRB.LESS_EQUAL, 0, name=f\"Adex_Obj_{i:d}\")\n",
    "                milp_timeout = config.timeout_final_milp if config.timeout_complete is None else (config.timeout_complete + start_milp - time.time())\n",
    "                model.setParam(GRB.Param.TimeLimit, milp_timeout)\n",
    "                model.setParam(GRB.Param.Cutoff, GRB.INFINITY)\n",
    "                model.setParam(GRB.Param.FeasibilityTol, 5e-5)\n",
    "                model.reset()\n",
    "                model.optimize()\n",
    "                sol_count = f\"{model.solcount:d}\" if hasattr(model, \"solcount\") else \"None\"\n",
    "                print(f\"MILP adex model status: {model.Status}, Model solution count: {sol_count}, Final solve time: {model.Runtime:.3f}\")\n",
    "                if model.solcount > 0:\n",
    "                    # This yields a guaranteed adversarial example\n",
    "                    adv_examples = [model.x[0:input_size]]\n",
    "                    adv_val = [None]\n",
    "                # The below portion enables the use of feasibility instead of optimization based  certification.\n",
    "                # This is not recommended as GUROBI is known to sometimes return spurious infeasibility\n",
    "                certify_with_feasibility = False\n",
    "                if certify_with_feasibility and model.status in [3, 4]: # model is infeasible\n",
    "                    for i in range(len(or_list)):\n",
    "                        model.remove(model.getConstrByName(f\"Adex_Obj_{i:d}\"))\n",
    "                    model.reset()\n",
    "                    model.optimize()\n",
    "                    if model.status not in [3, 4]: # not infeasible anymore\n",
    "                        print(f\"MILP adex model status without adex constraints: {model.Status}, Final solve time: {model.Runtime:.3f}\")\n",
    "                        warnings.warn(\"Model feasibility used for certification.\")\n",
    "                        or_result = True\n",
    "        if not or_result:\n",
    "            if len(adv_examples) > 0:\n",
    "                return False, adv_examples, adv_val\n",
    "            else:\n",
    "                return False, None, None\n",
    "    if len(non_adv_examples) > 0:\n",
    "        return True, non_adv_examples, non_adv_val\n",
    "    else:\n",
    "        return True, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd78afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_from_is_greater_tuple_old(is_greater_tuple, var_list, counter):\n",
    "    ### Define an objective for GUROBI based on an is_greater tuple\n",
    "    obj = LinExpr()\n",
    "    (i, j, k) = is_greater_tuple\n",
    "\n",
    "    if i == -1:  # var[i] > k\n",
    "        obj += 1 * var_list[counter + j] - float(k)\n",
    "    elif j == -1:  # var[j] < k\n",
    "        obj += float(k) - 1 * var_list[counter + i]\n",
    "    elif i != j:  # var[i] > var[j]\n",
    "        obj += 1 * var_list[counter + i]\n",
    "        obj += -1 * var_list[counter + j]\n",
    "    else:\n",
    "        assert False, f\"invalid constraint encountered {is_greater_tuple}\"\n",
    "    return obj"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
